{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xR1BrE1sqezE"
      },
      "source": [
        "#WESAD Downloading"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9Vw19LChqSWf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5cd2fb3b-9dc1-45a0-e56c-e01f6cf2bd20"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z3FT6AR4qVJU"
      },
      "outputs": [],
      "source": [
        "!wget -O /content/drive/MyDrive/Thesis/WESAD.zip 'https://uni-siegen.sciebo.de/s/HGdUkoNlW1Ub0Gx/download'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v_DWPIDzrB_K"
      },
      "outputs": [],
      "source": [
        "os.makedirs(extract_path, exist_ok=True)\n",
        "\n",
        "subjects = []\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "  names = [name for name in zip_ref.namelist() if '.pkl' in name]\n",
        "\n",
        "  for name in names:\n",
        "    zip_ref.extract(name, extract_path)\n",
        "names"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5uTl0dkDqeSI"
      },
      "source": [
        "#Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cEc_iPisqLO6"
      },
      "outputs": [],
      "source": [
        "!pip install neurokit2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MI5QV5x2qcPA"
      },
      "outputs": [],
      "source": [
        "import neurokit2 as nk\n",
        "import os\n",
        "import pickle\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from math import ceil, floor\n",
        "from scipy.signal import butter, filtfilt\n",
        "import time\n",
        "from datetime import datetime\n",
        "import zipfile\n",
        "import os\n",
        "import shutil"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Структура датасета\n",
        "\n",
        "```\n",
        "Это словарик со следующей структурой:\n",
        "{\n",
        "  \"subject\": \"SX\", где X - номер пациента,\n",
        "  \"signal\" : {\n",
        "    \"chest\" : {\n",
        "      \"ACC\" : (3847200, 3), #5 496 секунд (700 Гц)\n",
        "      \"ECG\" : (3847200, 1), #5 496 секунд (700 Гц)\n",
        "      \"EMG\" : (3847200, 1), #5 496 секунд (700 Гц)\n",
        "      \"EDA\" : (3847200, 1), #5 496 секунд (700 Гц)\n",
        "      \"Temp\" : (3847200, 1), #5 496 секунд (700 Гц)\n",
        "      \"Resp\" : (3847200, 1) #5 496 секунд (700 Гц)\n",
        "    },\n",
        "    \"wrist\" : {\n",
        "      \"ACC\" : (175872, 3), #5 496 секунд (32 Гц)\n",
        "      \"BVP\" : (351744, 1), #5 496 секунд (64 Гц)\n",
        "      \"EDA\" : (21984, 1), #5 496 секунд (4 Гц)\n",
        "      \"TEMP\" : (21984, 1) #5 496 секунд (4 Гц)\n",
        "    }\n",
        "  },\n",
        "  \"labels\" : (3847200, 1) #5 496 секунд (700 гц)\n",
        "}\n",
        "```"
      ],
      "metadata": {
        "id": "I_J93FT2vi2E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Signal:\n",
        "  \"\"\"\n",
        "  name - название сигнала\n",
        "  sampling - частота дискретизации (в Гц)\n",
        "  data - сам массив данных\n",
        "  \"\"\"\n",
        "  def __init__(self, name, sampling, data):\n",
        "    self.__name = name\n",
        "    self.__sampling = sampling\n",
        "\n",
        "    if 'EDA' in name:\n",
        "      self.__data = {\"Clean\": nk.eda_clean(data, sampling_rate=sampling)}\n",
        "      components = nk.eda_phasic(self.__data['Clean'], sampling_rate=sampling)\n",
        "      self.__data['Phasic'], self.__data['Tonic'] = components['EDA_Phasic'].values, components['EDA_Tonic'].values\n",
        "      self.__data['Peaks'], _ = nk.eda_peaks(self.__data['Clean'], sampling_rate=sampling)\n",
        "      self.__data['Peaks'] = self.__data['Peaks'][\"SCR_Peaks\"].values\n",
        "    elif \"BVP\" in name:\n",
        "      self.__data, _ = nk.ppg_process(data, sampling_rate=sampling)\n",
        "    elif \"ECG\" in name:\n",
        "      self.__data, _ = nk.ecg_process(data, sampling_rate=sampling)\n",
        "    else:\n",
        "      self.__data = data\n",
        "\n",
        "  def __str__(self):\n",
        "    return f\"Name: {self.__name}, Count: {len(self.__data)}, {self.__sampling} Hz\"\n",
        "\n",
        "  def get_freq(self):\n",
        "    return self.__sampling\n",
        "\n",
        "  def get_name(self):\n",
        "    return self.__name\n",
        "\n",
        "  def get_data(self):\n",
        "    return self.__data\n",
        "\n",
        "  def get_data_segment(self, time_begin, time_end, origin):\n",
        "    if \"EDA\" in self.__name:\n",
        "      return {\n",
        "          \"Clean\": self.__data[\"Clean\"][floor((time_begin - origin) * self.__sampling) : floor((time_end - origin) * self.__sampling) + 1],\n",
        "          \"Tonic\": self.__data[\"Tonic\"][floor((time_begin - origin) * self.__sampling) : floor((time_end - origin) * self.__sampling) + 1],\n",
        "          \"Phasic\": self.__data[\"Phasic\"][floor((time_begin - origin) * self.__sampling) : floor((time_end - origin) * self.__sampling) + 1],\n",
        "          \"Peaks\": self.__data[\"Peaks\"][floor((time_begin - origin) * self.__sampling) : floor((time_end - origin) * self.__sampling) + 1]\n",
        "      }\n",
        "    elif \"BVP\" in self.__name:\n",
        "      return {\n",
        "          \"Clean\": (self.__data[\"PPG_Clean\"].values)[floor((time_begin - origin) * self.__sampling) : floor((time_end - origin) * self.__sampling) + 1],\n",
        "          \"Rate\": (self.__data[\"PPG_Rate\"].values)[floor((time_begin - origin) * self.__sampling) : floor((time_end - origin) * self.__sampling) + 1],\n",
        "          \"Peaks\": (self.__data[\"PPG_Peaks\"].values)[floor((time_begin - origin) * self.__sampling) : floor((time_end - origin) * self.__sampling) + 1],\n",
        "      }\n",
        "    elif \"ECG\" in self.__name:\n",
        "      return {\n",
        "          \"Clean\": (self.__data[\"ECG_Clean\"].values)[floor((time_begin - origin) * self.__sampling) : floor((time_end - origin) * self.__sampling) + 1],\n",
        "          \"Rate\": (self.__data[\"ECG_Rate\"].values)[floor((time_begin - origin) * self.__sampling) : floor((time_end - origin) * self.__sampling) + 1],\n",
        "          \"Peaks\": (self.__data[\"ECG_R_Peaks\"].values)[floor((time_begin - origin) * self.__sampling) : floor((time_end - origin) * self.__sampling) + 1]\n",
        "      }\n",
        "    return self.__data[floor((time_begin - origin) * self.__sampling) : floor((time_end - origin) * self.__sampling) + 1]\n",
        "\n",
        "\"\"\"\n",
        "Класс одного участника эксперимента\n",
        "subject_keys = ['singal', 'label', 'subject']\n",
        "signal_keys = ['chest', 'wrist']\n",
        "chest_keys = ['ACC', 'ECG', 'EMG', 'EDA', 'Temp', 'Resp']\n",
        "wrist_keys = ['ACC', 'EDA', 'TEMP', 'BVP']\n",
        "\"\"\"\n",
        "class WesadSubject:\n",
        "  \"\"\"\n",
        "  Считываем данные одного пациента.\n",
        "\n",
        "  main_path - путь на биомедицинские данные пациентов\n",
        "  subject_name - номер пациента\n",
        "  \"\"\"\n",
        "  def __init__(self, main_path, subject_name, metric_conf=None):\n",
        "    with open(os.path.join(main_path, subject_name) + '/' + subject_name + '.pkl', 'rb') as file:\n",
        "          data = pickle.load(file, encoding='latin1')\n",
        "    self.__name = subject_name\n",
        "    self.__data = None\n",
        "\n",
        "    self.__metrics = {\n",
        "        \"chest\" : {\n",
        "          \"ACC\" : [\"MAX\", \"MIN\", \"STD\", \"MEAN\", \"RANGE\"],\n",
        "          \"ECG\" : [\"MAX\", \"MIN\", \"STD\", \"MEAN\", \"RANGE\"],\n",
        "          \"EMG\" : [\"MAX\", \"MIN\", \"STD\", \"MEAN\", \"RANGE\"],\n",
        "          \"EDA\" : [\"MAX\", \"MIN\", \"STD\", \"MEAN\", \"RANGE\"],\n",
        "          \"Temp\" : [\"MAX\", \"MIN\", \"STD\", \"MEAN\", \"RANGE\"],\n",
        "          \"Resp\" : [\"MAX\", \"MIN\", \"STD\", \"MEAN\", \"RANGE\"]\n",
        "        },\n",
        "        \"wrist\" : {\n",
        "            \"ACC\" : [\"MAX\", \"MIN\", \"STD\", \"MEAN\", \"RANGE\"],\n",
        "            \"EDA\" : [\"MAX\", \"MIN\", \"STD\", \"MEAN\", \"RANGE\"],\n",
        "            \"TEMP\" : [\"MAX\", \"MIN\", \"STD\", \"MEAN\", \"RANGE\"],\n",
        "            \"BVP\" : [\"MAX\", \"MIN\", \"STD\", \"MEAN\", \"RANGE\"]\n",
        "        }\n",
        "    } if not metric_conf else metric_conf\n",
        "\n",
        "    self.__restructure_data(data)\n",
        "\n",
        "  \"\"\"\n",
        "  Возвращает номер пациента в формате SX\n",
        "  \"\"\"\n",
        "  def get_name(self):\n",
        "    return self.__name\n",
        "\n",
        "  \"\"\"\n",
        "  Устанавливает конфигурацию для метрик\n",
        "  \"\"\"\n",
        "  def set_metrics_conf(self, conf):\n",
        "    for key in self.__metrics['wrist']:\n",
        "      self.__metrics['wrist'][key] = conf['wrist'][key]\n",
        "\n",
        "    for key in self.__metrics['chest']:\n",
        "      self.__metrics['chest'][key] = conf['chest'][key]\n",
        "\n",
        "  \"\"\"\n",
        "  Возвращает количество метрик\n",
        "  \"\"\"\n",
        "  def get_metric_count(self):\n",
        "    sm = 0\n",
        "\n",
        "    for key in self.__metrics['wrist']:\n",
        "      if key == \"ACC\":\n",
        "        sm += len(self.__metrics['wrist'][key]) * 3\n",
        "      else:\n",
        "        sm += len(self.__metrics['wrist'][key])\n",
        "\n",
        "    for key in self.__metrics['chest']:\n",
        "      if key == \"ACC\":\n",
        "        sm += len(self.__metrics['chest'][key]) * 3\n",
        "      else:\n",
        "        sm += len(self.__metrics['chest'][key])\n",
        "\n",
        "    return sm\n",
        "\n",
        "  \"\"\"\n",
        "  Вырезаем кусочек сигнала по данным границам, приводя их к требуемой частоте.\n",
        "  \"\"\"\n",
        "  def __extract_signal_method(self, time_interval, signal_name, signal):\n",
        "    freq = self.__sampling(signal_name)\n",
        "    return signal[time_interval[0] * freq : time_interval[1] * freq + 1]\n",
        "\n",
        "  \"\"\"\n",
        "  Реструктуризируем сигнал:\n",
        "  - Вырезаем только кусочки, которые классифицированы, как baseline и stress\n",
        "  - Разделяем данные на два класса: baseline (0) и stress (1)\n",
        "  - Разделяем сигналы между собой. Ex: ACC переводим из (:, 3) в  ACC_i : (:, i). См. структура датасета\n",
        "  \"\"\"\n",
        "  def __restructure_data(self, data):\n",
        "    baseline_class_mask = np.where((data['label'] == 1))[0]\n",
        "    baseline_start, baseline_end = baseline_class_mask[0], baseline_class_mask[-1]\n",
        "\n",
        "    stress_class_mask = np.where((data['label'] == 2))[0]\n",
        "    stress_start, stress_end = stress_class_mask[0], stress_class_mask[-1]\n",
        "\n",
        "    amusement_class_mask = np.where((data['label'] == 3))[0]\n",
        "    amusement_start, amusement_end = amusement_class_mask[0], amusement_class_mask[-1]\n",
        "\n",
        "    baseline_data = {\"time_interval\": (ceil(baseline_start / 700), floor(baseline_end / 700)), 'signals': {}}\n",
        "    stress_data = {\"time_interval\": (ceil(stress_start / 700), floor(stress_end / 700)), 'signals': {}}\n",
        "    amusement_data = {\"time_interval\": (ceil(amusement_start / 700), floor(amusement_end / 700)), 'signals': {}}\n",
        "\n",
        "    for device in data['signal']:\n",
        "      print('device: ', device)\n",
        "      for signal_type in data['signal'][device]:\n",
        "        print('\\ttype: ', signal_type)\n",
        "        for i in range(data['signal'][device][signal_type].shape[1]):\n",
        "          signal_name = '_'.join([device, signal_type, str(i)])\n",
        "          signal = data['signal'][device][signal_type][:, i]\n",
        "\n",
        "          baseline_data['signals'][signal_name] = self.__extract_signal_method(baseline_data['time_interval'], signal_name, signal)\n",
        "          stress_data['signals'][signal_name] = self.__extract_signal_method(stress_data['time_interval'], signal_name, signal)\n",
        "          amusement_data['signals'][signal_name] = self.__extract_signal_method(amusement_data['time_interval'], signal_name, signal)\n",
        "\n",
        "          if len(baseline_data['signals'][signal_name]) == 0:\n",
        "            raise ValueError(f\"baseline signal {signal_name} has a zero length. The length of the signal is {len(signal)} with time interval {baseline_data['time_interval']}\")\n",
        "          if len(stress_data['signals'][signal_name]) == 0:\n",
        "            raise ValueError(f\"stress signal {signal_name} has a zero length. The length of the signal is {len(signal)} with time interval {stress_data['time_interval']}\")\n",
        "          if len(amusement_data['signals'][signal_name]) == 0:\n",
        "            raise ValueError(f\"amusement signal {signal_name} has a zero length. The length of the signal is {len(signal)} with time interval {amusement_data['time_interval']}\")\n",
        "\n",
        "    self.__data = {'baseline': baseline_data, 'stress': stress_data, 'amusement': amusement_data}\n",
        "\n",
        "    for signal_name in self.__data['baseline']['signals']:\n",
        "      self.__data['baseline']['signals'][signal_name] = Signal(signal_name, self.__sampling(signal_name), self.__data['baseline']['signals'][signal_name])\n",
        "      self.__data['stress']['signals'][signal_name] = Signal(signal_name, self.__sampling(signal_name), self.__data['stress']['signals'][signal_name])\n",
        "      self.__data['amusement']['signals'][signal_name] = Signal(signal_name, self.__sampling(signal_name), self.__data['amusement']['signals'][signal_name])\n",
        "\n",
        "      if len(self.__data['baseline']['signals'][signal_name].get_data()) == 0:\n",
        "        raise ValueError(f\"baseline signal {signal_name} has a zero length.\")\n",
        "      if len(self.__data['stress']['signals'][signal_name].get_data()) == 0:\n",
        "        raise ValueError(f\"stress signal {signal_name} has a zero length.\")\n",
        "      if len(self.__data['amusement']['signals'][signal_name].get_data()) == 0:\n",
        "        raise ValueError(f\"amusement signal {signal_name} has a zero length.\")\n",
        "\n",
        "    print(f\"\\nИтого количество измерений в каждой классе:\\n\\tНейтральное состояние длится {self.__data['baseline']['time_interval'][1] - self.__data['baseline']['time_interval'][0] + 1} секунд.\\n\\tСтрессовое состояние длится {self.__data['stress']['time_interval'][1] - self.__data['stress']['time_interval'][0] + 1} секунд.\\n\\tСостояние веселья длится {self.__data['amusement']['time_interval'][1] - self.__data['amusement']['time_interval'][0] + 1} секунд.\")\n",
        "\n",
        "  \"\"\"\n",
        "  По названию и прибору измерений, записанному в signal_name определяет частоту дискретизации сигнала\n",
        "  \"\"\"\n",
        "  def __sampling(self, signal_name):\n",
        "    if signal_name.startswith(\"wrist_ACC\"):\n",
        "      return 32\n",
        "    if signal_name.startswith(\"wrist_BVP\"):\n",
        "      return 64\n",
        "    if signal_name.startswith(\"wrist_EDA\"):\n",
        "      return 4\n",
        "    if signal_name.startswith(\"wrist_TEMP\"):\n",
        "      return 4\n",
        "    return 700\n",
        "\n",
        "  \"\"\"\n",
        "  Формирование датасета размерности (n x 1 x m), где размерность - (количество всего объектов, количество timesteps, количество метрик)\n",
        "  \"\"\"\n",
        "  def preprocess_data_wots(self, window_size, timestep=45, signal_class=\"baseline\"):\n",
        "      if not self.__data:\n",
        "          raise ValueError(\"There is no data.\")\n",
        "      if signal_class not in ['baseline', 'stress', 'amusement']:\n",
        "          raise ValueError(f\"Incorrect signal_class name.\\nThe valid options are 'baseline', 'stress' and 'amusement', but '{signal_class}' was received.\")\n",
        "\n",
        "      start = self.__data[signal_class]['time_interval'][0] + window_size\n",
        "      end = self.__data[signal_class]['time_interval'][1] + 1\n",
        "      num_windows = ceil((end - start) / timestep)\n",
        "\n",
        "      num_metrics = self.get_metric_count()\n",
        "      dataset = np.zeros((num_windows, 1, num_metrics))\n",
        "\n",
        "      for i, right_border in enumerate(range(start, end, timestep)):\n",
        "          metrics = []\n",
        "          for signal_name in self.__data[signal_class]['signals']:\n",
        "              divice, name, _ = signal_name.split(\"_\")\n",
        "              if not self.__metrics[divice][name]:\n",
        "                continue\n",
        "\n",
        "              signal = self.__data[signal_class]['signals'][signal_name]\n",
        "\n",
        "\n",
        "              metrics.extend(self.make_metrics(\n",
        "                  signal.get_data_segment(right_border - window_size, right_border, self.__data[signal_class]['time_interval'][0]),\n",
        "                  signal.get_name(),\n",
        "                  signal.get_freq(),\n",
        "                  type=signal_class\n",
        "              ))\n",
        "          dataset[i, 0, :] = metrics\n",
        "\n",
        "      return dataset\n",
        "\n",
        "  \"\"\"\n",
        "  Формирование датасета размерности (n x t x m), где размерность - (количество всего объектов, количество timesteps, количество метрик)\n",
        "  \"\"\"\n",
        "  def preprocess_data_wts(self, inner_window_size, outer_window_size, inner_window_timestep=30, outer_window_timestep=45, signal_class=\"baseline\"):\n",
        "      if not self.__data:\n",
        "          raise ValueError(\"There is no data.\")\n",
        "      if inner_window_size > outer_window_size:\n",
        "          raise ValueError(\"The size of the inner window is more than the size of the outer window.\")\n",
        "      if signal_class not in ['baseline', 'stress', 'amusement']:\n",
        "          raise ValueError(f\"Incorrect signal_class name.\\nThe valid options are 'baseline' and 'stress', but '{signal_class}' was received.\")\n",
        "\n",
        "\n",
        "      start = self.__data[signal_class]['time_interval'][0] + outer_window_size\n",
        "      end = self.__data[signal_class]['time_interval'][1] + 1\n",
        "      num_outer_windows = floor((end - start) / outer_window_timestep) + 1\n",
        "      num_inner_windows = floor((outer_window_size - inner_window_size) / inner_window_timestep) + 1\n",
        "\n",
        "      num_metrics = self.get_metric_count()\n",
        "      dataset = np.zeros((num_outer_windows, num_inner_windows, num_metrics))\n",
        "\n",
        "      for i, outer_right_border in enumerate(range(start, end, outer_window_timestep)):\n",
        "          for j, inner_right_border in enumerate(np.arange(outer_right_border - outer_window_size + inner_window_size, outer_right_border + 1, inner_window_timestep)):\n",
        "              metrics = []\n",
        "              for signal_name in self.__data[signal_class]['signals']:\n",
        "                  divice, name, _ = signal_name.split(\"_\")\n",
        "                  if not self.__metrics[divice][name]:\n",
        "                    continue\n",
        "\n",
        "                  signal = self.__data[signal_class]['signals'][signal_name]\n",
        "                  window = signal.get_data_segment(inner_right_border - inner_window_size, inner_right_border, self.__data[signal_class]['time_interval'][0])\n",
        "                  self.last_time_interval = (inner_right_border - inner_window_size, inner_right_border, self.__data[signal_class]['time_interval'])\n",
        "\n",
        "                  if len(window) == 0:\n",
        "                    raise ValueError(f\"Given {signal_name} window has a zero length. Here's parameters:\\n\\ttime_interval: {self.__data[signal_class]['time_interval']},\\n\\tinner_window_bounders: {(inner_right_border - inner_window_size, inner_right_border)}\\n\\tlength of the signal: {len(signal.get_data())} with {signal.get_freq()} frequence.\")\n",
        "\n",
        "                  metrics.extend(self.make_metrics(\n",
        "                      window,\n",
        "                      signal.get_name(),\n",
        "                      signal.get_freq(),\n",
        "                      type=signal_class\n",
        "                  ))\n",
        "\n",
        "              dataset[i, j, :] = metrics\n",
        "\n",
        "      return dataset\n",
        "\n",
        "  \"\"\"\n",
        "  Генерация метрик\n",
        "  \"\"\"\n",
        "\n",
        "  def make_metrics(self, window, signal_name, freq, type='baseline'):\n",
        "      metrics = []\n",
        "      names = []\n",
        "\n",
        "      if \"wrist_EDA\" in signal_name and self.__metrics['wrist']['EDA'] or \"chest_EDA\" in signal_name and self.__metrics['chest']['EDA']:\n",
        "          device = signal_name.split(\"_\")[0]\n",
        "\n",
        "          for key in self.__metrics[device]['EDA']:\n",
        "            if key == \"EDA_MAX\":\n",
        "              metrics.append(np.max(window[\"Clean\"]))\n",
        "            elif key == \"EDA_MIN\":\n",
        "              metrics.append(np.min(window[\"Clean\"]))\n",
        "            elif key == \"EDA_MEAN\":\n",
        "              metrics.append(np.mean(window[\"Clean\"]))\n",
        "            elif key == \"EDA_STD\":\n",
        "              metrics.append(np.std(window[\"Clean\"]))\n",
        "            elif key == \"EDA_RANGE\":\n",
        "              metrics.append(np.max(window[\"Clean\"]) - np.min(window[\"Clean\"]))\n",
        "            elif key == \"SCR_RANGE\":\n",
        "              metrics.append(np.max(window[\"Phasic\"]) - np.min(window[\"Phasic\"]))\n",
        "            elif key == \"SCL_MEAN\":\n",
        "              metrics.append(np.mean(window[\"Tonic\"]))\n",
        "            elif key == \"SCL_STD\":\n",
        "              metrics.append(np.std(window[\"Tonic\"]))\n",
        "            elif key == \"SCL_MAX\":\n",
        "              metrics.append(np.max(window['Tonic']))\n",
        "            elif key == \"SCL_MIN\":\n",
        "              metrics.append(np.min(window['Tonic']))\n",
        "            elif key == \"SCR_PEAKS_NUMBER\":\n",
        "              metrics.append(np.sum(window['Peaks']))\n",
        "            elif key == \"SCR_MEAN\":\n",
        "              metrics.append(np.mean(window['Phasic']))\n",
        "            elif key == \"SCR_STD\":\n",
        "              metrics.append(np.std(window['Phasic']))\n",
        "            elif key == \"SCR_MIN\":\n",
        "              metrics.append(np.min(window['Phasic']))\n",
        "            elif key == \"SCR_MAX\":\n",
        "              metrics.append(np.max(window['Phasic']))\n",
        "            elif key == \"SCR_PEAKS_MEAN\":\n",
        "              metrics.append(np.mean(window['Clean'][window[\"Peaks\"] == 1]))\n",
        "            elif key == \"SCR_PEAKS_STD\":\n",
        "              metrics.append(np.std(window['Clean'][window[\"Peaks\"] == 1]))\n",
        "            elif key == \"SCR_PEAKS_MIN\":\n",
        "              metrics.append(np.min(window['Clean'][window[\"Peaks\"] == 1]))\n",
        "            elif key == \"SCR_PEAKS_MAX\":\n",
        "              metrics.append(np.max(window['Clean'][window[\"Peaks\"] == 1]))\n",
        "            elif key == \"ALSC\":\n",
        "              metrics.append(np.sum(np.sqrt((window['Phasic'][1:] - window['Phasic'][:-1]) ** 2 + 1)))\n",
        "            elif key == \"INSC\":\n",
        "              metrics.append(np.sum(np.abs(window['Phasic'])))\n",
        "            elif key == \"APSC\":\n",
        "              metrics.append(np.mean(window['Phasic'] ** 2))\n",
        "            elif key == \"RMSC\":\n",
        "              metrics.append(np.sqrt(np.mean(window['Phasic'] ** 2)))\n",
        "            else:\n",
        "              raise ValueError(f\"There is not {key} metric.\")\n",
        "            names.append(key)\n",
        "\n",
        "      elif \"BVP\" in signal_name or \"ECG\" in signal_name:\n",
        "          titles = []\n",
        "          temp_metrics = []\n",
        "          peaks_enough = (np.sum(window['Peaks']) >= 2)\n",
        "          divice, signal = ('wrist', \"BVP\") if \"BVP\" in signal_name else ('chest', \"ECG\")\n",
        "\n",
        "\n",
        "          for key in self.__metrics[divice][signal]:\n",
        "              if key == \"HRV_MEAN\":\n",
        "                  if peaks_enough:\n",
        "                    titles.append('HRV_MeanNN')\n",
        "                  else:\n",
        "                    temp_metrics.append(np.nan)\n",
        "              elif key == \"HRV_STD\":\n",
        "                  if peaks_enough:\n",
        "                    titles.append('HRV_SDNN')\n",
        "                  else:\n",
        "                    temp_metrics.append(0.0) #zero peaks, so zero std\n",
        "              elif key == \"pNN50\":\n",
        "                  if peaks_enough:\n",
        "                    titles.append('HRV_pNN50')\n",
        "                  else:\n",
        "                    temp_metrics.append(0.0)\n",
        "              elif key == \"HR_MEAN\":\n",
        "                  temp_metrics.append(np.mean(window['Rate']))\n",
        "              elif key == \"HR_STD\":\n",
        "                  temp_metrics.append(np.std(window['Rate']))\n",
        "              else:\n",
        "                  raise ValueError(f\"There is not {key} metric.\")\n",
        "              names.append(key)\n",
        "\n",
        "\n",
        "          if titles and np.sum(window['Peaks']) >= 2:\n",
        "            hrv = nk.hrv_time(window['Peaks'], sampling_rate=freq)\n",
        "            temp_metrics += hrv[titles].iloc[0].tolist()\n",
        "          elif titles:\n",
        "            print(len(temp_metrics))\n",
        "\n",
        "          metrics += temp_metrics\n",
        "\n",
        "      else:\n",
        "          if 'wrist' in signal_name:\n",
        "            for key in self.__metrics['wrist']:\n",
        "                if key in signal_name:\n",
        "                    for metric_name in self.__metrics['wrist'][key]:\n",
        "                        if metric_name == \"MAX\":\n",
        "                            metrics.append(np.max(window))\n",
        "                            names.append(f\"{key}_MAX\")\n",
        "                        elif metric_name == \"MIN\":\n",
        "                            metrics.append(np.min(window))\n",
        "                            names.append(f\"{key}_MIN\")\n",
        "                        elif metric_name == \"MEAN\":\n",
        "                            metrics.append(np.mean(window))\n",
        "                            names.append(f\"{key}_MEAN\")\n",
        "                        elif metric_name == \"STD\":\n",
        "                            metrics.append(np.std(window))\n",
        "                            names.append(f\"{key}_STD\")\n",
        "                        else:\n",
        "                            metrics.append(np.max(window) - np.min(window))\n",
        "                            names.append(f\"{key}_RANGE\")\n",
        "          else:\n",
        "            for key in self.__metrics['chest']:\n",
        "              if key in signal_name:\n",
        "                  for metric_name in self.__metrics['chest'][key]:\n",
        "                      if metric_name == \"MAX\":\n",
        "                          metrics.append(np.max(window))\n",
        "                          names.append(f\"{key}_MAX\")\n",
        "                      elif metric_name == \"MIN\":\n",
        "                          metrics.append(np.min(window))\n",
        "                          names.append(f\"{key}_MIN\")\n",
        "                      elif metric_name == \"MEAN\":\n",
        "                          metrics.append(np.mean(window))\n",
        "                          names.append(f\"{key}_MEAN\")\n",
        "                      elif metric_name == \"STD\":\n",
        "                          metrics.append(np.std(window))\n",
        "                          names.append(f\"{key}_STD\")\n",
        "                      else:\n",
        "                          metrics.append(np.max(window) - np.min(window))\n",
        "                          names.append(f\"{key}_RANGE\")\n",
        "      return metrics\n"
      ],
      "metadata": {
        "id": "5GXOvT5sXoNx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "zip_path = '/content/drive/MyDrive/Thesis/WESAD.zip'\n",
        "extract_path = '/content/drive/MyDrive/Thesis/Datasets/multiclass/chest_acc_'\n",
        "log_file = '/content/drive/MyDrive/Thesis/Results/multiclass_acc_dataset_time.txt'\n",
        "main_path = '/content/drive/MyDrive/Thesis/WESAD'"
      ],
      "metadata": {
        "id": "kwSHVVnYXaS6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "  names = [name for name in zip_ref.namelist() if '.pkl' in name]\n",
        "names"
      ],
      "metadata": {
        "id": "noqmTYlG2hl5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Допустимые метрики\n",
        "```\n",
        "\"EDA_MAX\", \"EDA_MIN\", \"EDA_MEAN\", \"EDA_STD\", \"EDA_RANGE\", \"SCR_RANGE\", \"SCL_MEAN\", \"SCL_STD\", \"SCR_PEAKS_NUMBER\", \"SCR_MEAN\", \"SCR_STD\", \"SCR_MIN\", \"SCR_MAX\", \"SCR_PEAKS_MEAN\", \"SCR_PEAKS_STD\", \"SCR_PEAKS_MIN\", \"SCR_PEAKS_MAX\", \"SCR_ONSETS_MEAN\", \"SCR_ONSETS_STD\", \"SCR_ONSETS_MIN\", \"SCR_ONSETS_MAX\", \"ALSC\", \"INSC\", \"APSC\", \"RMSC\"\n",
        "\"HR_MEAN\", \"HR_STD\", \"HRV_MEAN\", \"HRV_STD\", \"pNN50\", \"pNN20\", \"HTI\", \"RMSSD\", \"SD1\", \"SD2\", \"SDSD\"\n",
        "\"MAX\", \"MIN\", \"STD\", \"MEAN\", \"RANGE\"\n",
        "\"LF\", \"HF\", \"HFn\", \"LFHF\", \"MeanNN\", \"RMSSD\", \"SVI\"\n",
        "```"
      ],
      "metadata": {
        "id": "jwAObQ04MHiL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "signal_conf = {\n",
        "        \"chest\" : {\n",
        "          \"ACC\" : [],\n",
        "          \"ECG\" : [\"HR_MEAN\", \"HR_STD\", \"HRV_MEAN\", \"HRV_STD\", \"pNN50\"],\n",
        "          \"EMG\" : [],\n",
        "          \"EDA\" : [\"EDA_MEAN\", \"EDA_STD\", \"SCL_MEAN\", \"SCL_STD\", \"SCR_MEAN\", \"SCR_STD\", \"EDA_MAX\", \"EDA_MIN\", \"SCL_MAX\", \"SCL_MIN\", \"SCR_MAX\", \"SCR_MIN\"],\n",
        "          \"Temp\" : [],\n",
        "          \"Resp\" : []\n",
        "        },\n",
        "        \"wrist\" : {\n",
        "            \"ACC\" : [],\n",
        "            \"EDA\" : [],\n",
        "            \"TEMP\" : [],\n",
        "            \"BVP\" : []\n",
        "        }\n",
        "    }"
      ],
      "metadata": {
        "id": "OQjvOljZ3K6R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "subjects = [0] * len(names)\n",
        "\n",
        "for idx in range(len(subjects)):\n",
        "  print(f\"[{idx + 1}/{len(subjects)}] subject:\\n\")\n",
        "  subjects[idx] = WesadSubject(main_path, names[idx].split(\"/\")[1])"
      ],
      "metadata": {
        "id": "lBgfcqq1eDQz",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Создание датасета, где объекты являются статическим набором метрик"
      ],
      "metadata": {
        "id": "W0F7P_vnay3y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open(log_file, 'w') as f:\n",
        "  f.write(\"Time Log - \" + datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\") + \"\\n\\n\")\n",
        "\n",
        "dataset = {}\n",
        "\n",
        "time_start = time.time()\n",
        "\n",
        "for subject in subjects:\n",
        "      subject.set_metrics_conf(signal_conf)\n",
        "      baseline = subject.preprocess_data_wots(window_size = 60, timestep = 11, signal_class = \"baseline\")\n",
        "      stress = subject.preprocess_data_wots(window_size = 60, timestep = 6, signal_class = \"stress\")\n",
        "      amusement = subject.preprocess_data_wots(window_size = 60, timestep = 3, signal_class = \"amusement\")\n",
        "\n",
        "      data = np.concatenate((baseline, stress, amusement), axis = 0)\n",
        "\n",
        "      dataset[subject.get_name()] = {}\n",
        "      dataset[subject.get_name()]['data'] = data\n",
        "      dataset[subject.get_name()]['label'] = np.array([0] * len(baseline) + [1] * len(stress) + [2] * len(amusement))\n",
        "\n",
        "      with open(extract_path + f\"dataset.pkl\", 'wb') as ofile:\n",
        "        pickle.dump(dataset, ofile)\n",
        "\n",
        "with open(log_file, \"a\") as f:\n",
        "  f.write(f\"Dataset without timesteps\\n\")\n",
        "  f.write(f\"Time: {time.time() - time_start} sec\\n\\n\")"
      ],
      "metadata": {
        "id": "1b5sSLLsR9OU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Создание датасета, где объекты являются временными рядами метрик"
      ],
      "metadata": {
        "id": "JjW3DAtXbBMV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for window in range(15, 46, 15):\n",
        "  for timestep_num in range(2, 9):\n",
        "    dataset = {}\n",
        "    inner_window_timestep = (60 - window) / (timestep_num - 1)\n",
        "    if window < inner_window_timestep:\n",
        "      continue\n",
        "    print(f\"window_size: {window}, timestep_num: {timestep_num}, inner_window_step: {inner_window_timestep}\")\n",
        "    for subject in subjects:\n",
        "      subject.set_metrics_conf(signal_conf)\n",
        "\n",
        "      baseline = subject.preprocess_data_wts(inner_window_size = window, outer_window_size = 60, inner_window_timestep=inner_window_timestep, outer_window_timestep=11, signal_class=\"baseline\")\n",
        "      stress = subject.preprocess_data_wts(inner_window_size = window, outer_window_size = 60, inner_window_timestep=inner_window_timestep, outer_window_timestep=6, signal_class=\"stress\")\n",
        "      amusement = subject.preprocess_data_wts(inner_window_size = window, outer_window_size = 60, inner_window_timestep=inner_window_timestep, outer_window_timestep=3, signal_class=\"amusement\")\n",
        "\n",
        "      data = np.concatenate((baseline, stress, amusement), axis = 0)\n",
        "\n",
        "      dataset[subject.get_name()] = {}\n",
        "      dataset[subject.get_name()]['data'] = data\n",
        "      dataset[subject.get_name()]['label'] = np.array([0] * len(baseline) + [1] * len(stress) + [2] * len(amusement))\n",
        "\n",
        "    with open(extract_path + f\"dataset_{window}_{timestep_num}{'_bug' if window < inner_window_timestep else ''}.pkl\", 'wb') as ofile:\n",
        "      pickle.dump(dataset, ofile)\n",
        "\n",
        "    with open(log_file, \"a\") as f:\n",
        "      f.write(f\"Dataset with {timestep_num} timestpes and an internal window length of {window} seconds\\n\")\n",
        "      f.write(f\"Time: {time.time() - time_start} sec\\n\\n\")"
      ],
      "metadata": {
        "id": "zK-hHhTaaVsA"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}