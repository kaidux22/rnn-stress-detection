{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hmRADIBLVGFU",
        "outputId": "85863126-5e06-4a8d-b054-e59da271c478"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        },
        "collapsed": true,
        "id": "tOQc1H_FZwvw",
        "outputId": "2b815702-4a83-46b9-a8eb-bf3f1ad659f4"
      },
      "outputs": [
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-7e7fc67cc157>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush_and_unmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mflush_and_unmount\u001b[0;34m(timeout_ms)\u001b[0m\n\u001b[1;32m     89\u001b[0m       \u001b[0mstderr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_subprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPIPE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m   )\n\u001b[0;32m---> 91\u001b[0;31m   \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommunicate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mmount\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_DEBUG\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'flush_and_unmount: out: {}\\nerr: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/subprocess.py\u001b[0m in \u001b[0;36mcommunicate\u001b[0;34m(self, input, timeout)\u001b[0m\n\u001b[1;32m   1207\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1208\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1209\u001b[0;31m                 \u001b[0mstdout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstderr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_communicate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mendtime\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1210\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1211\u001b[0m                 \u001b[0;31m# https://bugs.python.org/issue25942\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/subprocess.py\u001b[0m in \u001b[0;36m_communicate\u001b[0;34m(self, input, endtime, orig_timeout)\u001b[0m\n\u001b[1;32m   2113\u001b[0m                             'failed to raise TimeoutExpired.')\n\u001b[1;32m   2114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2115\u001b[0;31m                     \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2116\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_timeout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mendtime\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morig_timeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstdout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstderr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/selectors.py\u001b[0m in \u001b[0;36mselect\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    413\u001b[0m         \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    414\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 415\u001b[0;31m             \u001b[0mfd_event_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_selector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    416\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mInterruptedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    417\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "drive.flush_and_unmount()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SXtGr4dLdIpi",
        "outputId": "a31d9461-dff0-4ddd-d37b-e5edf5a54026"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7da72cd50fd0>"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "import torch.nn as nn\n",
        "import matplotlib.pyplot as plt\n",
        "import random as rd\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import torch.optim as optim\n",
        "import random\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pickle\n",
        "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score, roc_auc_score\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from datetime import datetime\n",
        "from sklearn.utils import shuffle\n",
        "import time\n",
        "from sklearn.preprocessing import label_binarize\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "import traceback\n",
        "\n",
        "# Set the seed for reproducibility\n",
        "seed = 42\n",
        "torch.manual_seed(seed)\n",
        "np.random.seed(seed)\n",
        "random.seed(seed)\n",
        "\n",
        "# Generate permutations\n",
        "gen = torch.Generator()\n",
        "gen.manual_seed(seed)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "yt2k7wqDaGkr"
      },
      "outputs": [],
      "source": [
        "path = \"/content/drive/MyDrive/Thesis/Datasets/multiclass\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ahbyMYHZJodb"
      },
      "source": [
        "#Binary Classification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iMwvTRXlUQPp"
      },
      "outputs": [],
      "source": [
        "class LSTMStressBinDetector(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size=128, num_layers=2):\n",
        "        super().__init__()\n",
        "        self.lstm1 = nn.LSTM(\n",
        "            input_size=input_size,\n",
        "            hidden_size=hidden_size,\n",
        "            num_layers=num_layers,\n",
        "            batch_first=True\n",
        "        )\n",
        "\n",
        "        self.fc = nn.Linear(hidden_size, 1)\n",
        "        self.sig = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        out, _ = self.lstm1(x)\n",
        "        out = self.fc(out[:, -1, :])\n",
        "        out = self.sig(out)\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "19aO-mtZJss7"
      },
      "outputs": [],
      "source": [
        "def data_processing_binclass(extract_path, window, step):\n",
        "  if step == 1:\n",
        "    path = f\"{extract_path}/chest_dataset.pkl\"\n",
        "  else:\n",
        "    path = f\"{extract_path}/chest_dataset_{window}_{step}.pkl\"\n",
        "\n",
        "  try:\n",
        "    with open(path, 'rb') as file:\n",
        "      dataset = pickle.load(file, encoding='latin1')\n",
        "  except FileNotFoundError:\n",
        "    return None\n",
        "\n",
        "  X_train, Y_train, X_test, Y_test = None, None, None, None\n",
        "  for key in dataset:\n",
        "    binclass_mask = np.where(dataset[key]['label'] != 2)\n",
        "    y = dataset[key]['label'][binclass_mask]\n",
        "    arrays = train_test_split(dataset[key]['data'][binclass_mask], y, random_state=42, test_size=0.15, stratify=y)\n",
        "    X_train = np.concatenate((arrays[0], X_train), axis=0) if X_train is not None else arrays[0]\n",
        "    X_test = np.concatenate((arrays[1], X_test), axis=0) if X_test is not None else arrays[1]\n",
        "    Y_train = np.concatenate((arrays[2], Y_train), axis=0) if Y_train is not None else arrays[2]\n",
        "    Y_test = np.concatenate((arrays[3], Y_test), axis=0) if Y_test is not None else arrays[3]\n",
        "\n",
        "  X_train, Y_train = shuffle(X_train, Y_train, random_state=42)\n",
        "  X_test, Y_test = shuffle(X_test, Y_test, random_state=42)\n",
        "\n",
        "  X_train = torch.tensor(X_train, dtype=torch.float32)\n",
        "  X_test = torch.tensor(X_test, dtype=torch.float32)\n",
        "  Y_train = torch.tensor(Y_train, dtype=torch.float32)\n",
        "  Y_test = torch.tensor(Y_test, dtype=torch.float32)\n",
        "\n",
        "  # Для обучающего набора\n",
        "  train_mask = ~torch.isnan(X_train).any(dim=(1, 2))\n",
        "  X_train_clean = X_train[train_mask]\n",
        "  Y_train_clean = Y_train[train_mask]\n",
        "\n",
        "  # Для тестового набора\n",
        "  test_mask = ~torch.isnan(X_test).any(dim=(1, 2))\n",
        "  X_test_clean = X_test[test_mask]\n",
        "  Y_test_clean = Y_test[test_mask]\n",
        "\n",
        "  return X_train_clean, Y_train_clean, X_test_clean, Y_test_clean"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oO4VPHdMGkib"
      },
      "outputs": [],
      "source": [
        "def binclass_train_model(X_train, Y_train, X_val, Y_val, input_size, num_epochs=300, patience=30):\n",
        "    model = LSTMStressBinDetector(input_size)\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    model.to(device)\n",
        "\n",
        "    criterion = nn.BCELoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=1e-2)\n",
        "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=5, min_lr=1e-6)\n",
        "\n",
        "    train_losses = []\n",
        "    val_losses = []\n",
        "    best_val_loss = float('inf')\n",
        "    best_model_state = None\n",
        "    early_stop_counter = 0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = model(X_train)\n",
        "        loss = criterion(outputs.view(-1), Y_train)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Validation\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            val_outputs = model(X_val)\n",
        "            val_loss = criterion(val_outputs.view(-1), Y_val)\n",
        "\n",
        "        scheduler.step(val_loss)\n",
        "\n",
        "        # Logging\n",
        "        train_losses.append(loss.item())\n",
        "        val_losses.append(val_loss.item())\n",
        "\n",
        "        # Save best model for this fold\n",
        "        if val_loss < best_val_loss:\n",
        "            best_val_loss = val_loss\n",
        "            best_model_state = model.state_dict()\n",
        "            early_stop_counter = 0\n",
        "        else:\n",
        "            early_stop_counter += 1\n",
        "\n",
        "        if (epoch + 1) % 10 == 0:\n",
        "            print(f'Epoch [{epoch+1}/{num_epochs}], Train Loss: {loss.item():.4f}, Val Loss: {val_loss.item():.4f}')\n",
        "\n",
        "        # Early stopping for this fold\n",
        "        if early_stop_counter >= patience and epoch > 50:\n",
        "            print(f\"Early stopping at epoch {epoch+1} (no improvement for {patience} epochs)\")\n",
        "            break\n",
        "\n",
        "    # Load best weights for this fold\n",
        "    model.load_state_dict(best_model_state)\n",
        "    return model, train_losses, val_losses\n",
        "\n",
        "def binclass_training_with_cv(X_train, Y_train, X_test, Y_test, n_splits=10, num_epochs=300, patience=30):\n",
        "    input_size = X_train.shape[2]\n",
        "    kf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
        "    fold_metrics = []\n",
        "\n",
        "    for fold, (train_idx, val_idx) in enumerate(kf.split(X_train, Y_train)):\n",
        "        print(f\"\\n--- Fold {fold + 1}/{n_splits} ---\")\n",
        "\n",
        "        # Split data\n",
        "        X_fold_train, X_fold_val = X_train[train_idx], X_train[val_idx]\n",
        "        Y_fold_train, Y_fold_val = Y_train[train_idx], Y_train[val_idx]\n",
        "\n",
        "        # Train with early stopping per fold\n",
        "        model, train_loss, val_loss = binclass_train_model(\n",
        "            X_fold_train, Y_fold_train,\n",
        "            X_fold_val, Y_fold_val,\n",
        "            input_size,\n",
        "            num_epochs=num_epochs,\n",
        "            patience=patience\n",
        "        )\n",
        "\n",
        "        # Evaluate on test set (optional per fold)\n",
        "        fold_test_metrics = binclass_evaluate(model, X_test, Y_test)\n",
        "        fold_metrics.append(fold_test_metrics)\n",
        "        print(f\"Fold {fold + 1} Test Metrics:\", fold_test_metrics)\n",
        "\n",
        "    return fold_metrics\n",
        "\n",
        "def binclass_evaluate(model, X, Y, plot_cm=True, class_names=None):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        outputs = model(X)\n",
        "        preds = (outputs > 0.5).float().cpu().numpy()\n",
        "        probs = outputs.cpu().numpy()\n",
        "        labels = Y.cpu().numpy()\n",
        "\n",
        "    # Вычисляем Confusion Matrix\n",
        "    cm = confusion_matrix(labels, preds)\n",
        "\n",
        "    return {\n",
        "        'accuracy': accuracy_score(labels, preds),\n",
        "        'precision': precision_score(labels, preds),\n",
        "        'recall': recall_score(labels, preds),\n",
        "        'f1': f1_score(labels, preds),\n",
        "        'auroc': roc_auc_score(labels, probs),\n",
        "        \"confusion_matrix\": cm\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r41zoUvovSWI"
      },
      "outputs": [],
      "source": [
        "def run_experiment(path, window, timestep):\n",
        "    ans = data_processing_binclass(path, window, timestep)\n",
        "\n",
        "    if ans is None:\n",
        "      return None\n",
        "\n",
        "    X_train, Y_train, X_test, Y_test = ans\n",
        "    # Записываем в лог параметры\n",
        "    with open(log_file, \"a\") as f:\n",
        "      f.write(f\"\\n=== Window: {window}, Timestep: {timestep} ===\\n\")\n",
        "\n",
        "    print(f\"\\nProcessing window={window}, timestep={timestep}\")\n",
        "\n",
        "    try:\n",
        "      metrics = binclass_training_with_cv(X_train, Y_train, X_test, Y_test, n_splits=10)\n",
        "\n",
        "      # Записываем в лог метрики\n",
        "      with open(log_file, \"a\") as f:\n",
        "        f.write(f\"Metrics: {metrics}\\n\")\n",
        "        f.write(f\"Accuracy: {np.mean([fold['accuracy'] for fold in metrics]):.4f}, Precision: {np.mean([fold['precision'] for fold in metrics]):.4f}, Recall: {np.mean([fold['recall'] for fold in metrics]):.4f},  F1: {np.mean([fold['f1'] for fold in metrics]):.4f}, AUROC: {np.mean([fold['auroc'] for fold in metrics]):.4f}\\n\")\n",
        "\n",
        "        print(f\"Final Test Metrics: {np.mean([fold['accuracy'] for fold in metrics]):.4f}, Precision: {np.mean([fold['precision'] for fold in metrics]):.4f}, Recall: {np.mean([fold['recall'] for fold in metrics]):.4f},  F1: {np.mean([fold['f1'] for fold in metrics]):.4f}, AUROC: {np.mean([fold['auroc'] for fold in metrics]):.4f}\\n\")\n",
        "      return metrics\n",
        "\n",
        "    except Exception as e:\n",
        "      with open(log_file, \"a\") as f:\n",
        "        f.write(f\"Error: {str(e)}\\n\")\n",
        "        print(f\"Error for window={window}, timestep={timestep}: {str(e)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CLT6VqklMsgp",
        "outputId": "b6a24e1e-12af-4db1-d5f6-7db7a0350033"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Processing window=45, timestep=7\n",
            "\n",
            "--- Fold 1/10 ---\n",
            "Epoch [10/300], Train Loss: 0.4895, Val Loss: 0.4618\n",
            "Epoch [20/300], Train Loss: 0.4223, Val Loss: 0.3711\n",
            "Epoch [30/300], Train Loss: 0.3147, Val Loss: 0.3248\n",
            "Epoch [40/300], Train Loss: 0.2814, Val Loss: 0.2699\n",
            "Epoch [50/300], Train Loss: 0.3021, Val Loss: 0.2868\n",
            "Epoch [60/300], Train Loss: 0.2710, Val Loss: 0.2834\n",
            "Epoch [70/300], Train Loss: 0.2674, Val Loss: 0.2816\n",
            "Early stopping at epoch 72 (no improvement for 30 epochs)\n",
            "Fold 1 Test Metrics: {'accuracy': 0.8896103896103896, 'precision': 0.8991228070175439, 'recall': 0.8798283261802575, 'f1': 0.8893709327548807, 'auroc': np.float64(0.9641096763311281), 'confusion_matrix': array([[206,  23],\n",
            "       [ 28, 205]])}\n",
            "\n",
            "--- Fold 2/10 ---\n",
            "Epoch [10/300], Train Loss: 0.5017, Val Loss: 0.6587\n",
            "Epoch [20/300], Train Loss: 0.5533, Val Loss: 0.5340\n",
            "Epoch [30/300], Train Loss: 0.4971, Val Loss: 0.4906\n",
            "Epoch [40/300], Train Loss: 0.4963, Val Loss: 0.4899\n",
            "Epoch [50/300], Train Loss: 0.4962, Val Loss: 0.4897\n",
            "Early stopping at epoch 52 (no improvement for 30 epochs)\n",
            "Fold 2 Test Metrics: {'accuracy': 0.8246753246753247, 'precision': 0.9578313253012049, 'recall': 0.6824034334763949, 'f1': 0.7969924812030075, 'auroc': np.float64(0.9177240099705756), 'confusion_matrix': array([[222,   7],\n",
            "       [ 74, 159]])}\n",
            "\n",
            "--- Fold 3/10 ---\n",
            "Epoch [10/300], Train Loss: 0.5964, Val Loss: 0.4666\n",
            "Epoch [20/300], Train Loss: 0.3752, Val Loss: 0.3997\n",
            "Epoch [30/300], Train Loss: 0.5093, Val Loss: 0.4963\n",
            "Epoch [40/300], Train Loss: 0.3988, Val Loss: 0.4116\n",
            "Epoch [50/300], Train Loss: 0.3957, Val Loss: 0.4106\n",
            "Early stopping at epoch 52 (no improvement for 30 epochs)\n",
            "Fold 3 Test Metrics: {'accuracy': 0.8203463203463204, 'precision': 0.9464285714285714, 'recall': 0.6824034334763949, 'f1': 0.7930174563591023, 'auroc': np.float64(0.9324549731056844), 'confusion_matrix': array([[220,   9],\n",
            "       [ 74, 159]])}\n",
            "\n",
            "--- Fold 4/10 ---\n",
            "Epoch [10/300], Train Loss: 0.6479, Val Loss: 0.4763\n",
            "Epoch [20/300], Train Loss: 0.3508, Val Loss: 0.3535\n",
            "Epoch [30/300], Train Loss: 0.3352, Val Loss: 0.3397\n",
            "Epoch [40/300], Train Loss: 0.3114, Val Loss: 0.3153\n",
            "Epoch [50/300], Train Loss: 0.3023, Val Loss: 0.3084\n",
            "Epoch [60/300], Train Loss: 0.2998, Val Loss: 0.3058\n",
            "Epoch [70/300], Train Loss: 0.2974, Val Loss: 0.3042\n",
            "Epoch [80/300], Train Loss: 0.2954, Val Loss: 0.3022\n",
            "Epoch [90/300], Train Loss: 0.2935, Val Loss: 0.3006\n",
            "Epoch [100/300], Train Loss: 0.2917, Val Loss: 0.2995\n",
            "Epoch [110/300], Train Loss: 0.2898, Val Loss: 0.2976\n",
            "Epoch [120/300], Train Loss: 0.2878, Val Loss: 0.2955\n",
            "Epoch [130/300], Train Loss: 0.2857, Val Loss: 0.2935\n",
            "Epoch [140/300], Train Loss: 0.2834, Val Loss: 0.2912\n",
            "Epoch [150/300], Train Loss: 0.2811, Val Loss: 0.2890\n",
            "Epoch [160/300], Train Loss: 0.2786, Val Loss: 0.2867\n",
            "Epoch [170/300], Train Loss: 0.2762, Val Loss: 0.2844\n",
            "Epoch [180/300], Train Loss: 0.2737, Val Loss: 0.2820\n",
            "Epoch [190/300], Train Loss: 0.2712, Val Loss: 0.2795\n",
            "Epoch [200/300], Train Loss: 0.2687, Val Loss: 0.2769\n",
            "Epoch [210/300], Train Loss: 0.2663, Val Loss: 0.2743\n",
            "Epoch [220/300], Train Loss: 0.2639, Val Loss: 0.2717\n",
            "Epoch [230/300], Train Loss: 0.2615, Val Loss: 0.2688\n",
            "Epoch [240/300], Train Loss: 0.2586, Val Loss: 0.2655\n",
            "Epoch [250/300], Train Loss: 0.2550, Val Loss: 0.2610\n",
            "Epoch [260/300], Train Loss: 0.2510, Val Loss: 0.2568\n",
            "Epoch [270/300], Train Loss: 0.2475, Val Loss: 0.2531\n",
            "Epoch [280/300], Train Loss: 0.2436, Val Loss: 0.2495\n",
            "Epoch [290/300], Train Loss: 0.2394, Val Loss: 0.2461\n",
            "Epoch [300/300], Train Loss: 0.2349, Val Loss: 0.2423\n",
            "Fold 4 Test Metrics: {'accuracy': 0.8917748917748918, 'precision': 0.9552238805970149, 'recall': 0.8240343347639485, 'f1': 0.8847926267281107, 'auroc': np.float64(0.9671645707217422), 'confusion_matrix': array([[220,   9],\n",
            "       [ 41, 192]])}\n",
            "\n",
            "--- Fold 5/10 ---\n",
            "Epoch [10/300], Train Loss: 0.5452, Val Loss: 0.4071\n",
            "Epoch [20/300], Train Loss: 0.4016, Val Loss: 0.3880\n",
            "Epoch [30/300], Train Loss: 0.3634, Val Loss: 0.3685\n",
            "Epoch [40/300], Train Loss: 0.3339, Val Loss: 0.3384\n",
            "Epoch [50/300], Train Loss: 0.3209, Val Loss: 0.3310\n",
            "Epoch [60/300], Train Loss: 0.3147, Val Loss: 0.3237\n",
            "Epoch [70/300], Train Loss: 0.3118, Val Loss: 0.3234\n",
            "Epoch [80/300], Train Loss: 0.3111, Val Loss: 0.3236\n",
            "Epoch [90/300], Train Loss: 0.3111, Val Loss: 0.3236\n",
            "Early stopping at epoch 94 (no improvement for 30 epochs)\n",
            "Fold 5 Test Metrics: {'accuracy': 0.854978354978355, 'precision': 0.8807339449541285, 'recall': 0.8240343347639485, 'f1': 0.8514412416851441, 'auroc': np.float64(0.9498285135970913), 'confusion_matrix': array([[203,  26],\n",
            "       [ 41, 192]])}\n",
            "\n",
            "--- Fold 6/10 ---\n",
            "Epoch [10/300], Train Loss: 0.6571, Val Loss: 0.6478\n",
            "Epoch [20/300], Train Loss: 0.3718, Val Loss: 0.3957\n",
            "Epoch [30/300], Train Loss: 0.3286, Val Loss: 0.3278\n",
            "Epoch [40/300], Train Loss: 0.4977, Val Loss: 0.4961\n",
            "Epoch [50/300], Train Loss: 0.4172, Val Loss: 0.4102\n",
            "Epoch [60/300], Train Loss: 0.4144, Val Loss: 0.4088\n",
            "Early stopping at epoch 62 (no improvement for 30 epochs)\n",
            "Fold 6 Test Metrics: {'accuracy': 0.8268398268398268, 'precision': 0.8311688311688312, 'recall': 0.8240343347639485, 'f1': 0.8275862068965517, 'auroc': np.float64(0.9328672901400004), 'confusion_matrix': array([[190,  39],\n",
            "       [ 41, 192]])}\n",
            "\n",
            "--- Fold 7/10 ---\n",
            "Epoch [10/300], Train Loss: 0.4255, Val Loss: 0.4623\n",
            "Epoch [20/300], Train Loss: 0.4080, Val Loss: 0.3246\n",
            "Epoch [30/300], Train Loss: 0.3368, Val Loss: 0.2561\n",
            "Epoch [40/300], Train Loss: 0.5622, Val Loss: 0.3279\n",
            "Epoch [50/300], Train Loss: 0.3442, Val Loss: 0.3038\n",
            "Epoch [60/300], Train Loss: 0.3383, Val Loss: 0.2995\n",
            "Early stopping at epoch 63 (no improvement for 30 epochs)\n",
            "Fold 7 Test Metrics: {'accuracy': 0.854978354978355, 'precision': 1.0, 'recall': 0.7124463519313304, 'f1': 0.8320802005012531, 'auroc': np.float64(0.9509155312330153), 'confusion_matrix': array([[229,   0],\n",
            "       [ 67, 166]])}\n",
            "\n",
            "--- Fold 8/10 ---\n",
            "Epoch [10/300], Train Loss: 0.5820, Val Loss: 0.5176\n",
            "Epoch [20/300], Train Loss: 0.4334, Val Loss: 0.4290\n",
            "Epoch [30/300], Train Loss: 0.3724, Val Loss: 0.3887\n",
            "Epoch [40/300], Train Loss: 0.3563, Val Loss: 0.3869\n",
            "Epoch [50/300], Train Loss: 0.3502, Val Loss: 0.3768\n",
            "Epoch [60/300], Train Loss: 0.3484, Val Loss: 0.3724\n",
            "Epoch [70/300], Train Loss: 0.3466, Val Loss: 0.3729\n",
            "Epoch [80/300], Train Loss: 0.3465, Val Loss: 0.3730\n",
            "Epoch [90/300], Train Loss: 0.3465, Val Loss: 0.3730\n",
            "Early stopping at epoch 91 (no improvement for 30 epochs)\n",
            "Fold 8 Test Metrics: {'accuracy': 0.8571428571428571, 'precision': 0.9033816425120773, 'recall': 0.8025751072961373, 'f1': 0.85, 'auroc': np.float64(0.9296062372322282), 'confusion_matrix': array([[209,  20],\n",
            "       [ 46, 187]])}\n",
            "\n",
            "--- Fold 9/10 ---\n",
            "Epoch [10/300], Train Loss: 0.4925, Val Loss: 0.4643\n",
            "Epoch [20/300], Train Loss: 0.4084, Val Loss: 0.3880\n",
            "Epoch [30/300], Train Loss: 0.3264, Val Loss: 0.3927\n",
            "Epoch [40/300], Train Loss: 0.3136, Val Loss: 0.3227\n",
            "Epoch [50/300], Train Loss: 0.2266, Val Loss: 0.2862\n",
            "Epoch [60/300], Train Loss: 0.3165, Val Loss: 0.3142\n",
            "Epoch [70/300], Train Loss: 0.2862, Val Loss: 0.2994\n",
            "Early stopping at epoch 79 (no improvement for 30 epochs)\n",
            "Fold 9 Test Metrics: {'accuracy': 0.8874458874458875, 'precision': 0.9593908629441624, 'recall': 0.8111587982832618, 'f1': 0.8790697674418605, 'auroc': np.float64(0.9609235901568679), 'confusion_matrix': array([[221,   8],\n",
            "       [ 44, 189]])}\n",
            "\n",
            "--- Fold 10/10 ---\n",
            "Epoch [10/300], Train Loss: 0.5232, Val Loss: 0.5210\n",
            "Epoch [20/300], Train Loss: 0.3953, Val Loss: 0.4490\n",
            "Epoch [30/300], Train Loss: 0.3679, Val Loss: 0.3901\n",
            "Epoch [40/300], Train Loss: 0.3296, Val Loss: 0.3567\n",
            "Epoch [50/300], Train Loss: 0.2991, Val Loss: 0.3126\n",
            "Epoch [60/300], Train Loss: 0.2630, Val Loss: 0.2747\n",
            "Epoch [70/300], Train Loss: 0.2453, Val Loss: 0.2735\n",
            "Epoch [80/300], Train Loss: 0.2292, Val Loss: 0.2425\n",
            "Epoch [90/300], Train Loss: 0.2097, Val Loss: 0.2316\n",
            "Epoch [100/300], Train Loss: 0.1981, Val Loss: 0.2131\n",
            "Epoch [110/300], Train Loss: 0.1852, Val Loss: 0.2037\n",
            "Epoch [120/300], Train Loss: 0.1803, Val Loss: 0.1860\n",
            "Epoch [130/300], Train Loss: 0.1756, Val Loss: 0.1834\n",
            "Epoch [140/300], Train Loss: 0.1890, Val Loss: 0.1937\n",
            "Epoch [150/300], Train Loss: 0.1610, Val Loss: 0.1700\n",
            "Epoch [160/300], Train Loss: 0.1605, Val Loss: 0.1688\n",
            "Epoch [170/300], Train Loss: 0.1595, Val Loss: 0.1676\n",
            "Epoch [180/300], Train Loss: 0.1585, Val Loss: 0.1665\n",
            "Epoch [190/300], Train Loss: 0.1576, Val Loss: 0.1654\n",
            "Epoch [200/300], Train Loss: 0.1568, Val Loss: 0.1645\n",
            "Epoch [210/300], Train Loss: 0.1559, Val Loss: 0.1635\n",
            "Epoch [220/300], Train Loss: 0.1551, Val Loss: 0.1627\n",
            "Epoch [230/300], Train Loss: 0.1542, Val Loss: 0.1617\n",
            "Epoch [240/300], Train Loss: 0.1534, Val Loss: 0.1607\n",
            "Epoch [250/300], Train Loss: 0.1526, Val Loss: 0.1597\n",
            "Epoch [260/300], Train Loss: 0.1517, Val Loss: 0.1587\n",
            "Epoch [270/300], Train Loss: 0.1509, Val Loss: 0.1577\n",
            "Epoch [280/300], Train Loss: 0.1500, Val Loss: 0.1567\n",
            "Epoch [290/300], Train Loss: 0.1492, Val Loss: 0.1558\n",
            "Epoch [300/300], Train Loss: 0.1484, Val Loss: 0.1549\n",
            "Fold 10 Test Metrics: {'accuracy': 0.9393939393939394, 'precision': 0.9475982532751092, 'recall': 0.9313304721030042, 'f1': 0.9393939393939394, 'auroc': np.float64(0.9887737316565774), 'confusion_matrix': array([[217,  12],\n",
            "       [ 16, 217]])}\n",
            "Final Test Metrics: 0.8647, Precision: 0.9281, Recall: 0.7974,  F1: 0.8544, AUROC: 0.9494\n",
            "\n",
            "\n",
            "Processing window=45, timestep=8\n",
            "\n",
            "--- Fold 1/10 ---\n",
            "Epoch [10/300], Train Loss: 0.5659, Val Loss: 0.5181\n",
            "Epoch [20/300], Train Loss: 0.3714, Val Loss: 0.3442\n",
            "Epoch [30/300], Train Loss: 0.3077, Val Loss: 0.3193\n",
            "Epoch [40/300], Train Loss: 0.3082, Val Loss: 0.3180\n",
            "Epoch [50/300], Train Loss: 0.3059, Val Loss: 0.3336\n",
            "Epoch [60/300], Train Loss: 0.2941, Val Loss: 0.3184\n",
            "Early stopping at epoch 67 (no improvement for 30 epochs)\n",
            "Fold 1 Test Metrics: {'accuracy': 0.8463203463203464, 'precision': 0.8491379310344828, 'recall': 0.8454935622317596, 'f1': 0.8473118279569892, 'auroc': np.float64(0.9501658638978954), 'confusion_matrix': array([[194,  35],\n",
            "       [ 36, 197]])}\n",
            "\n",
            "--- Fold 2/10 ---\n",
            "Epoch [10/300], Train Loss: 0.6589, Val Loss: 0.6597\n",
            "Epoch [20/300], Train Loss: 0.6558, Val Loss: 0.6562\n",
            "Epoch [30/300], Train Loss: 0.6554, Val Loss: 0.6560\n",
            "Epoch [40/300], Train Loss: 0.6553, Val Loss: 0.6560\n",
            "Epoch [50/300], Train Loss: 0.6553, Val Loss: 0.6559\n",
            "Early stopping at epoch 52 (no improvement for 30 epochs)\n",
            "Fold 2 Test Metrics: {'accuracy': 0.8138528138528138, 'precision': 0.893048128342246, 'recall': 0.7167381974248928, 'f1': 0.7952380952380952, 'auroc': np.float64(0.9198043368255336), 'confusion_matrix': array([[209,  20],\n",
            "       [ 66, 167]])}\n",
            "\n",
            "--- Fold 3/10 ---\n",
            "Epoch [10/300], Train Loss: 0.5034, Val Loss: 0.5169\n",
            "Epoch [20/300], Train Loss: 0.3788, Val Loss: 0.3917\n",
            "Epoch [30/300], Train Loss: 0.3513, Val Loss: 0.3489\n",
            "Epoch [40/300], Train Loss: 0.3133, Val Loss: 0.3574\n",
            "Epoch [50/300], Train Loss: 0.2812, Val Loss: 0.3125\n",
            "Epoch [60/300], Train Loss: 0.2415, Val Loss: 0.2999\n",
            "Epoch [70/300], Train Loss: 0.2163, Val Loss: 0.2767\n",
            "Epoch [80/300], Train Loss: 0.2087, Val Loss: 0.2703\n",
            "Epoch [90/300], Train Loss: 0.2083, Val Loss: 0.2696\n",
            "Epoch [100/300], Train Loss: 0.2078, Val Loss: 0.2687\n",
            "Epoch [110/300], Train Loss: 0.2074, Val Loss: 0.2680\n",
            "Epoch [120/300], Train Loss: 0.2069, Val Loss: 0.2673\n",
            "Epoch [130/300], Train Loss: 0.2065, Val Loss: 0.2666\n",
            "Epoch [140/300], Train Loss: 0.2062, Val Loss: 0.2661\n",
            "Epoch [150/300], Train Loss: 0.2058, Val Loss: 0.2655\n",
            "Epoch [160/300], Train Loss: 0.2055, Val Loss: 0.2650\n",
            "Epoch [170/300], Train Loss: 0.2051, Val Loss: 0.2645\n",
            "Epoch [180/300], Train Loss: 0.2048, Val Loss: 0.2641\n",
            "Epoch [190/300], Train Loss: 0.2045, Val Loss: 0.2637\n",
            "Epoch [200/300], Train Loss: 0.2042, Val Loss: 0.2633\n",
            "Epoch [210/300], Train Loss: 0.2039, Val Loss: 0.2629\n",
            "Epoch [220/300], Train Loss: 0.2036, Val Loss: 0.2625\n",
            "Epoch [230/300], Train Loss: 0.2033, Val Loss: 0.2621\n",
            "Epoch [240/300], Train Loss: 0.2030, Val Loss: 0.2618\n",
            "Epoch [250/300], Train Loss: 0.2027, Val Loss: 0.2614\n",
            "Epoch [260/300], Train Loss: 0.2024, Val Loss: 0.2610\n",
            "Epoch [270/300], Train Loss: 0.2021, Val Loss: 0.2606\n",
            "Epoch [280/300], Train Loss: 0.2018, Val Loss: 0.2602\n",
            "Epoch [290/300], Train Loss: 0.2015, Val Loss: 0.2598\n",
            "Epoch [300/300], Train Loss: 0.2012, Val Loss: 0.2594\n",
            "Fold 3 Test Metrics: {'accuracy': 0.9090909090909091, 'precision': 0.9360730593607306, 'recall': 0.8798283261802575, 'f1': 0.9070796460176991, 'auroc': np.float64(0.9768915043949247), 'confusion_matrix': array([[215,  14],\n",
            "       [ 28, 205]])}\n",
            "\n",
            "--- Fold 4/10 ---\n",
            "Epoch [10/300], Train Loss: 0.6853, Val Loss: 0.4762\n",
            "Epoch [20/300], Train Loss: 0.5445, Val Loss: 0.5466\n",
            "Epoch [30/300], Train Loss: 0.5118, Val Loss: 0.5122\n",
            "Epoch [40/300], Train Loss: 0.5099, Val Loss: 0.5112\n",
            "Epoch [50/300], Train Loss: 0.5097, Val Loss: 0.5110\n",
            "Early stopping at epoch 52 (no improvement for 30 epochs)\n",
            "Fold 4 Test Metrics: {'accuracy': 0.8506493506493507, 'precision': 0.8306451612903226, 'recall': 0.8841201716738197, 'f1': 0.8565488565488566, 'auroc': np.float64(0.9333170905410724), 'confusion_matrix': array([[187,  42],\n",
            "       [ 27, 206]])}\n",
            "\n",
            "--- Fold 5/10 ---\n",
            "Epoch [10/300], Train Loss: 0.4744, Val Loss: 0.5823\n",
            "Epoch [20/300], Train Loss: 0.4703, Val Loss: 0.4292\n",
            "Epoch [30/300], Train Loss: 0.3587, Val Loss: 0.4000\n",
            "Epoch [40/300], Train Loss: 0.3447, Val Loss: 0.3450\n",
            "Epoch [50/300], Train Loss: 0.3147, Val Loss: 0.3314\n",
            "Epoch [60/300], Train Loss: 0.3089, Val Loss: 0.3231\n",
            "Epoch [70/300], Train Loss: 0.3044, Val Loss: 0.3146\n",
            "Epoch [80/300], Train Loss: 0.3003, Val Loss: 0.3088\n",
            "Epoch [90/300], Train Loss: 0.2955, Val Loss: 0.3033\n",
            "Epoch [100/300], Train Loss: 0.2901, Val Loss: 0.2972\n",
            "Epoch [110/300], Train Loss: 0.2838, Val Loss: 0.2897\n",
            "Epoch [120/300], Train Loss: 0.2766, Val Loss: 0.2803\n",
            "Epoch [130/300], Train Loss: 0.2680, Val Loss: 0.2690\n",
            "Epoch [140/300], Train Loss: 0.2570, Val Loss: 0.2560\n",
            "Epoch [150/300], Train Loss: 0.2433, Val Loss: 0.2419\n",
            "Epoch [160/300], Train Loss: 0.2304, Val Loss: 0.2315\n",
            "Epoch [170/300], Train Loss: 0.2186, Val Loss: 0.2279\n",
            "Epoch [180/300], Train Loss: 0.2147, Val Loss: 0.2278\n",
            "Epoch [190/300], Train Loss: 0.1958, Val Loss: 0.2187\n",
            "Epoch [200/300], Train Loss: 0.1858, Val Loss: 0.2133\n",
            "Epoch [210/300], Train Loss: 0.1775, Val Loss: 0.2114\n",
            "Epoch [220/300], Train Loss: 0.1732, Val Loss: 0.2119\n",
            "Epoch [230/300], Train Loss: 0.1722, Val Loss: 0.2110\n",
            "Epoch [240/300], Train Loss: 0.1721, Val Loss: 0.2110\n",
            "Early stopping at epoch 247 (no improvement for 30 epochs)\n",
            "Fold 5 Test Metrics: {'accuracy': 0.9285714285714286, 'precision': 0.9587155963302753, 'recall': 0.8969957081545065, 'f1': 0.926829268292683, 'auroc': np.float64(0.980920966321195), 'confusion_matrix': array([[220,   9],\n",
            "       [ 24, 209]])}\n",
            "\n",
            "--- Fold 6/10 ---\n",
            "Epoch [10/300], Train Loss: 0.4963, Val Loss: 0.4949\n",
            "Epoch [20/300], Train Loss: 0.3909, Val Loss: 0.3453\n",
            "Epoch [30/300], Train Loss: 0.3433, Val Loss: 0.3464\n",
            "Epoch [40/300], Train Loss: 0.2962, Val Loss: 0.3012\n",
            "Epoch [50/300], Train Loss: 0.2782, Val Loss: 0.2624\n",
            "Epoch [60/300], Train Loss: 0.2650, Val Loss: 0.2518\n",
            "Epoch [70/300], Train Loss: 0.2541, Val Loss: 0.2320\n",
            "Epoch [80/300], Train Loss: 0.2439, Val Loss: 0.2232\n",
            "Epoch [90/300], Train Loss: 0.2325, Val Loss: 0.2146\n",
            "Epoch [100/300], Train Loss: 0.2193, Val Loss: 0.2037\n",
            "Epoch [110/300], Train Loss: 0.2053, Val Loss: 0.1904\n",
            "Epoch [120/300], Train Loss: 0.1908, Val Loss: 0.1770\n",
            "Epoch [130/300], Train Loss: 0.1768, Val Loss: 0.1684\n",
            "Epoch [140/300], Train Loss: 0.1664, Val Loss: 0.1589\n",
            "Epoch [150/300], Train Loss: 0.1538, Val Loss: 0.1501\n",
            "Epoch [160/300], Train Loss: 0.1440, Val Loss: 0.1429\n",
            "Epoch [170/300], Train Loss: 0.1402, Val Loss: 0.1423\n",
            "Epoch [180/300], Train Loss: 0.1326, Val Loss: 0.1402\n",
            "Epoch [190/300], Train Loss: 0.1320, Val Loss: 0.1391\n",
            "Epoch [200/300], Train Loss: 0.1316, Val Loss: 0.1391\n",
            "Epoch [210/300], Train Loss: 0.1315, Val Loss: 0.1391\n",
            "Epoch [220/300], Train Loss: 0.1315, Val Loss: 0.1391\n",
            "Early stopping at epoch 223 (no improvement for 30 epochs)\n",
            "Fold 6 Test Metrics: {'accuracy': 0.922077922077922, 'precision': 0.9377777777777778, 'recall': 0.9055793991416309, 'f1': 0.9213973799126638, 'auroc': np.float64(0.9803961991866109), 'confusion_matrix': array([[215,  14],\n",
            "       [ 22, 211]])}\n",
            "\n",
            "--- Fold 7/10 ---\n",
            "Epoch [10/300], Train Loss: 0.5776, Val Loss: 0.4058\n",
            "Epoch [20/300], Train Loss: 0.4436, Val Loss: 0.3848\n",
            "Epoch [30/300], Train Loss: 0.4516, Val Loss: 0.4210\n",
            "Epoch [40/300], Train Loss: 0.4448, Val Loss: 0.4142\n",
            "Epoch [50/300], Train Loss: 0.4444, Val Loss: 0.4137\n",
            "Early stopping at epoch 52 (no improvement for 30 epochs)\n",
            "Fold 7 Test Metrics: {'accuracy': 0.7813852813852814, 'precision': 0.9647887323943662, 'recall': 0.5879828326180258, 'f1': 0.7306666666666667, 'auroc': np.float64(0.8830518957212736), 'confusion_matrix': array([[224,   5],\n",
            "       [ 96, 137]])}\n",
            "\n",
            "--- Fold 8/10 ---\n",
            "Epoch [10/300], Train Loss: 0.6686, Val Loss: 0.6663\n",
            "Epoch [20/300], Train Loss: 0.6583, Val Loss: 0.6572\n",
            "Epoch [30/300], Train Loss: 0.6545, Val Loss: 0.6529\n",
            "Epoch [40/300], Train Loss: 0.6499, Val Loss: 0.6477\n",
            "Epoch [50/300], Train Loss: 0.6443, Val Loss: 0.6413\n",
            "Epoch [60/300], Train Loss: 0.6373, Val Loss: 0.6336\n",
            "Epoch [70/300], Train Loss: 0.6291, Val Loss: 0.6251\n",
            "Epoch [80/300], Train Loss: 0.6196, Val Loss: 0.6153\n",
            "Epoch [90/300], Train Loss: 0.6081, Val Loss: 0.6035\n",
            "Epoch [100/300], Train Loss: 0.5942, Val Loss: 0.5889\n",
            "Epoch [110/300], Train Loss: 0.5775, Val Loss: 0.5716\n",
            "Epoch [120/300], Train Loss: 0.5574, Val Loss: 0.5508\n",
            "Epoch [130/300], Train Loss: 0.5337, Val Loss: 0.5265\n",
            "Epoch [140/300], Train Loss: 0.5060, Val Loss: 0.4988\n",
            "Epoch [150/300], Train Loss: 0.4753, Val Loss: 0.4690\n",
            "Epoch [160/300], Train Loss: 0.4434, Val Loss: 0.4399\n",
            "Epoch [170/300], Train Loss: 0.4130, Val Loss: 0.4139\n",
            "Epoch [180/300], Train Loss: 0.3863, Val Loss: 0.3909\n",
            "Epoch [190/300], Train Loss: 0.3634, Val Loss: 0.3714\n",
            "Epoch [200/300], Train Loss: 0.3431, Val Loss: 0.3536\n",
            "Epoch [210/300], Train Loss: 0.3233, Val Loss: 0.3346\n",
            "Epoch [220/300], Train Loss: 0.3035, Val Loss: 0.3153\n",
            "Epoch [230/300], Train Loss: 0.2828, Val Loss: 0.2937\n",
            "Epoch [240/300], Train Loss: 0.2613, Val Loss: 0.2686\n",
            "Epoch [250/300], Train Loss: 0.2396, Val Loss: 0.2446\n",
            "Epoch [260/300], Train Loss: 0.2208, Val Loss: 0.2293\n",
            "Epoch [270/300], Train Loss: 0.2095, Val Loss: 0.2144\n",
            "Epoch [280/300], Train Loss: 0.2016, Val Loss: 0.2072\n",
            "Epoch [290/300], Train Loss: 0.1967, Val Loss: 0.2045\n",
            "Epoch [300/300], Train Loss: 0.1926, Val Loss: 0.1957\n",
            "Fold 8 Test Metrics: {'accuracy': 0.9329004329004329, 'precision': 0.9508928571428571, 'recall': 0.9141630901287554, 'f1': 0.9321663019693655, 'auroc': np.float64(0.9855314204321832), 'confusion_matrix': array([[218,  11],\n",
            "       [ 20, 213]])}\n",
            "\n",
            "--- Fold 9/10 ---\n",
            "Epoch [10/300], Train Loss: 0.4293, Val Loss: 0.5347\n",
            "Epoch [20/300], Train Loss: 0.4195, Val Loss: 0.4543\n",
            "Epoch [30/300], Train Loss: 0.3909, Val Loss: 0.4271\n",
            "Epoch [40/300], Train Loss: 0.3831, Val Loss: 0.4188\n",
            "Epoch [50/300], Train Loss: 0.3750, Val Loss: 0.4100\n",
            "Epoch [60/300], Train Loss: 0.3682, Val Loss: 0.4020\n",
            "Epoch [70/300], Train Loss: 0.3628, Val Loss: 0.3951\n",
            "Epoch [80/300], Train Loss: 0.3579, Val Loss: 0.3894\n",
            "Epoch [90/300], Train Loss: 0.3531, Val Loss: 0.3843\n",
            "Epoch [100/300], Train Loss: 0.3484, Val Loss: 0.3791\n",
            "Epoch [110/300], Train Loss: 0.3435, Val Loss: 0.3737\n",
            "Epoch [120/300], Train Loss: 0.3384, Val Loss: 0.3682\n",
            "Epoch [130/300], Train Loss: 0.3331, Val Loss: 0.3625\n",
            "Epoch [140/300], Train Loss: 0.3275, Val Loss: 0.3571\n",
            "Epoch [150/300], Train Loss: 0.3221, Val Loss: 0.3528\n",
            "Epoch [160/300], Train Loss: 0.3171, Val Loss: 0.3489\n",
            "Epoch [170/300], Train Loss: 0.3124, Val Loss: 0.3454\n",
            "Epoch [180/300], Train Loss: 0.3081, Val Loss: 0.3425\n",
            "Epoch [190/300], Train Loss: 0.3040, Val Loss: 0.3399\n",
            "Epoch [200/300], Train Loss: 0.3000, Val Loss: 0.3379\n",
            "Epoch [210/300], Train Loss: 0.2959, Val Loss: 0.3362\n",
            "Epoch [220/300], Train Loss: 0.2918, Val Loss: 0.3348\n",
            "Epoch [230/300], Train Loss: 0.2876, Val Loss: 0.3334\n",
            "Epoch [240/300], Train Loss: 0.2833, Val Loss: 0.3319\n",
            "Epoch [250/300], Train Loss: 0.2788, Val Loss: 0.3301\n",
            "Epoch [260/300], Train Loss: 0.2743, Val Loss: 0.3281\n",
            "Epoch [270/300], Train Loss: 0.2697, Val Loss: 0.3257\n",
            "Epoch [280/300], Train Loss: 0.2651, Val Loss: 0.3229\n",
            "Epoch [290/300], Train Loss: 0.2606, Val Loss: 0.3198\n",
            "Epoch [300/300], Train Loss: 0.2562, Val Loss: 0.3164\n",
            "Fold 9 Test Metrics: {'accuracy': 0.8852813852813853, 'precision': 0.9245283018867925, 'recall': 0.8412017167381974, 'f1': 0.8808988764044944, 'auroc': np.float64(0.962816500178046), 'confusion_matrix': array([[213,  16],\n",
            "       [ 37, 196]])}\n",
            "\n",
            "--- Fold 10/10 ---\n",
            "Epoch [10/300], Train Loss: 0.5098, Val Loss: 0.5450\n",
            "Epoch [20/300], Train Loss: 0.3870, Val Loss: 0.4149\n",
            "Epoch [30/300], Train Loss: 0.3680, Val Loss: 0.4324\n",
            "Epoch [40/300], Train Loss: 0.3649, Val Loss: 0.4306\n",
            "Epoch [50/300], Train Loss: 0.3648, Val Loss: 0.4305\n",
            "Early stopping at epoch 52 (no improvement for 30 epochs)\n",
            "Fold 10 Test Metrics: {'accuracy': 0.8354978354978355, 'precision': 0.953757225433526, 'recall': 0.7081545064377682, 'f1': 0.812807881773399, 'auroc': np.float64(0.9347602001611784), 'confusion_matrix': array([[221,   8],\n",
            "       [ 68, 165]])}\n",
            "Final Test Metrics: 0.8706, Precision: 0.9199, Recall: 0.8180,  F1: 0.8611, AUROC: 0.9508\n",
            "\n",
            "\n",
            "Saved files:\n",
            "- Training logs: /content/drive/MyDrive/Thesis/Results/chest_binclass_log_v1.txt\n",
            "- All results: /content/drive/MyDrive/Thesis/Results/chest_binclass_v1.pkl\n"
          ]
        }
      ],
      "source": [
        "# Создаем папку для результатов (если нет)\n",
        "!mkdir -p /content/drive/MyDrive/Thesis/Results\n",
        "\n",
        "# Инициализируем переменные для сохранения\n",
        "all_steps = None\n",
        "all_results = None\n",
        "log_file = \"/content/drive/MyDrive/Thesis/Results/chest_binclass_log_v1.txt\"\n",
        "\n",
        "# Открываем файл для записи логов\n",
        "with open(log_file, \"a\") as f:\n",
        "    f.write(\"Training Log - \" + datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\") + \"\\n\\n\")\n",
        "\n",
        "chest_binclass_dict = {}\n",
        "\n",
        "#chest_binclass_dict[(15, 1)] = run_experiment(path, 0, 1)\n",
        "#chest_binclass_dict[(30, 1)] = chest_binclass_dict[(15, 1)]\n",
        "#chest_binclass_dict[(45, 1)] = chest_binclass_dict[(15, 1)]\n",
        "\n",
        "for window in range(15, 46, 15):\n",
        "    for timestep in range(2, 9):\n",
        "        if window == 15 or window == 30 or window == 45 and timestep < 7:\n",
        "          continue\n",
        "        chest_binclass_dict[(window, timestep)] = run_experiment(path, window, timestep)\n",
        "\n",
        "with open('/content/drive/MyDrive/Thesis/Results/chest_binclass_v1.pkl', 'wb') as f:\n",
        "    pickle.dump(chest_binclass_dict, f)\n",
        "\n",
        "# Выводим информацию о сохраненных файлах\n",
        "print(\"\\nSaved files:\")\n",
        "print(f\"- Training logs: {log_file}\")\n",
        "print(f\"- All results: /content/drive/MyDrive/Thesis/Results/chest_binclass_v1.pkl\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yhu0NmpjbtSj"
      },
      "outputs": [],
      "source": [
        "# Plotting function\n",
        "def plot_metrics(steps, results, x_axis_index, x_label):\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    x_values = steps[:, x_axis_index]\n",
        "\n",
        "    plt.plot(x_values, results[:, 0], label='Accuracy', marker='o')\n",
        "    plt.plot(x_values, results[:, 1], label='Precision', marker='o')\n",
        "    plt.plot(x_values, results[:, 2], label='Recall', marker='o')\n",
        "    plt.plot(x_values, results[:, 3], label='F1 Score', marker='o')\n",
        "    plt.plot(x_values, results[:, 4], label='AUROC', marker='o')\n",
        "\n",
        "    plt.xlabel(x_label)\n",
        "    plt.ylabel('Metric Value')\n",
        "    plt.title(f'Metrics vs {x_label}')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x_3Ji7p7oYcw"
      },
      "source": [
        "#Многоклассовая классификация"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "8rAHbS92nJ-4"
      },
      "outputs": [],
      "source": [
        "class LSTMStressMultiDetector1h(nn.Module):\n",
        "    def __init__(self, input_size=15, hidden_size=200, num_layers=1, num_classes=3):\n",
        "        super().__init__()\n",
        "        # Первый LSTM слой\n",
        "        self.first_lstm = nn.LSTM(\n",
        "            input_size=input_size,\n",
        "            hidden_size=hidden_size,\n",
        "            num_layers=1,\n",
        "            batch_first=True\n",
        "        )\n",
        "\n",
        "        self.fc = nn.Linear(hidden_size, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out, _ = self.first_lstm(x)\n",
        "        out = self.fc(out[:, -1, :])\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class LSTMStressMultiDetector4h(nn.Module):\n",
        "    def __init__(self, input_size=15, hidden_size=200, num_layers=4, num_classes=3):\n",
        "        super().__init__()\n",
        "        cur_hidden_size = hidden_size\n",
        "        # Первый LSTM слой\n",
        "        self.first_lstm = nn.LSTM(\n",
        "            input_size=input_size,\n",
        "            hidden_size=cur_hidden_size,\n",
        "            num_layers=1,\n",
        "            batch_first=True\n",
        "        )\n",
        "        cur_hidden_size -= 50\n",
        "\n",
        "        self.hid_lstm = []\n",
        "        self.dropout = []\n",
        "        for _ in range(num_layers - 2):\n",
        "          self.hid_lstm.append(\n",
        "              nn.LSTM(\n",
        "            input_size=cur_hidden_size + 50,\n",
        "            hidden_size=cur_hidden_size,\n",
        "            num_layers=1,\n",
        "            batch_first=True\n",
        "            )\n",
        "          )\n",
        "\n",
        "          self.dropout.append(\n",
        "              nn.Dropout(0.2)\n",
        "          )\n",
        "\n",
        "          cur_hidden_size -= 50\n",
        "\n",
        "        self.last_lstm = nn.LSTM(\n",
        "            input_size=cur_hidden_size + 50,\n",
        "            hidden_size=cur_hidden_size,\n",
        "            num_layers=1,\n",
        "            batch_first=True\n",
        "        )\n",
        "\n",
        "        self.fc = nn.Linear(cur_hidden_size, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out, _ = self.first_lstm(x)\n",
        "\n",
        "        for i in range(len(self.hid_lstm)):\n",
        "          out, _ = self.hid_lstm[i](out)\n",
        "          out = self.dropout[i](out)\n",
        "\n",
        "        out, _ = self.last_lstm(out)\n",
        "        out = self.fc(out[:, -1, :])\n",
        "        return out"
      ],
      "metadata": {
        "id": "LJruWynzPFeK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "T5SCwvFynoD-"
      },
      "outputs": [],
      "source": [
        "def data_processing_multiclass(extract_path, window, step, class_number=3):\n",
        "    if step == 1:\n",
        "      path = f\"{extract_path}/chest_acc_dataset.pkl\"\n",
        "    else:\n",
        "      path = f\"{extract_path}/chest_acc_dataset_{window}_{step}.pkl\"\n",
        "    try:\n",
        "        with open(path, 'rb') as file:\n",
        "            dataset = pickle.load(file, encoding='latin1')\n",
        "    except Exception as e:\n",
        "        print(e)\n",
        "        return None\n",
        "\n",
        "    X_train, Y_train, X_test, Y_test = None, None, None, None\n",
        "    for key in dataset:\n",
        "        y = np.eye(class_number)[dataset[key]['label'].astype(int)]\n",
        "        arrays = train_test_split(dataset[key]['data'], y, random_state=42, test_size=0.15, stratify=y.argmax(axis=1))\n",
        "        X_train = np.concatenate((X_train, arrays[0]), axis=0) if X_train is not None else arrays[0]\n",
        "        X_test = np.concatenate((X_test, arrays[1]), axis=0) if X_test is not None else arrays[1]\n",
        "        Y_train = np.concatenate((Y_train, arrays[2]), axis=0) if Y_train is not None else arrays[2]\n",
        "        Y_test = np.concatenate((Y_test, arrays[3]), axis=0) if Y_test is not None else arrays[3]\n",
        "\n",
        "    X_train, Y_train = shuffle(X_train, Y_train, random_state=42)\n",
        "    X_test, Y_test = shuffle(X_test, Y_test, random_state=42)\n",
        "\n",
        "    X_train = torch.tensor(X_train, dtype=torch.float32)\n",
        "    X_test = torch.tensor(X_test, dtype=torch.float32)\n",
        "    Y_train = torch.tensor(Y_train, dtype=torch.float32)\n",
        "    Y_test = torch.tensor(Y_test, dtype=torch.float32)\n",
        "\n",
        "    # Для обучающего набора\n",
        "    train_mask = ~torch.isnan(X_train).any(dim=(1, 2))\n",
        "    X_train_clean = X_train[train_mask]\n",
        "    Y_train_clean = Y_train[train_mask]\n",
        "\n",
        "    # Для тестового набора\n",
        "    test_mask = ~torch.isnan(X_test).any(dim=(1, 2))\n",
        "    X_test_clean = X_test[test_mask]\n",
        "    Y_test_clean = Y_test[test_mask]\n",
        "\n",
        "    return X_train_clean, Y_train_clean, X_test_clean, Y_test_clean"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "OHVM_A0Iob2g"
      },
      "outputs": [],
      "source": [
        "def multiclass_train_model(X_train, Y_train, X_val, Y_val, input_size, num_epochs=300, patience=30):\n",
        "    model = LSTMStressMultiDetector1h(input_size, num_classes=3)\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    model.to(device)\n",
        "\n",
        "    # Изменяем функцию потерь на CrossEntropyLoss (не нужно softmax в модели)\n",
        "    class_counts = torch.bincount(Y_train.argmax(dim=1))\n",
        "    class_weights = 1. / class_counts.float()\n",
        "    criterion = nn.CrossEntropyLoss(weight=class_weights.to(device))\n",
        "    optimizer = optim.Adam(model.parameters(), lr=1e-2)\n",
        "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=5, min_lr=1e-6)\n",
        "\n",
        "    train_losses = []\n",
        "    val_losses = []\n",
        "    best_val_loss = float('inf')\n",
        "    best_model_state = None\n",
        "    early_stop_counter = 0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = model(X_train)\n",
        "        loss = criterion(outputs, Y_train.argmax(dim=1))  # Используем argmax для классов\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Validation\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            val_outputs = model(X_val)\n",
        "            val_loss = criterion(val_outputs, Y_val.argmax(dim=1))\n",
        "\n",
        "        scheduler.step(val_loss)\n",
        "\n",
        "        # Logging\n",
        "        train_losses.append(loss.item())\n",
        "        val_losses.append(val_loss.item())\n",
        "\n",
        "        # Save best model for this fold\n",
        "        if val_loss < best_val_loss:\n",
        "            best_val_loss = val_loss\n",
        "            best_model_state = model.state_dict()\n",
        "            early_stop_counter = 0\n",
        "        else:\n",
        "            early_stop_counter += 1\n",
        "\n",
        "        if (epoch + 1) % 10 == 0:\n",
        "            print(f'Epoch [{epoch+1}/{num_epochs}], Train Loss: {loss.item():.4f}, Val Loss: {val_loss.item():.4f}')\n",
        "\n",
        "        # Early stopping for this fold\n",
        "        if early_stop_counter >= patience and epoch > 50:\n",
        "            print(f\"Early stopping at epoch {epoch+1} (no improvement for {patience} epochs)\")\n",
        "            break\n",
        "\n",
        "    # Load best weights for this fold\n",
        "    model.load_state_dict(best_model_state)\n",
        "    return model, train_losses, val_losses, epoch\n",
        "\n",
        "def multiclass_evaluate(model, X, Y, plot_cm=True, class_names=None):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        outputs = model(X)\n",
        "        preds = outputs.argmax(dim=1).cpu().numpy()\n",
        "        logits = outputs.cpu().numpy()\n",
        "        labels = Y.argmax(dim=1).cpu().numpy()\n",
        "\n",
        "    probs = torch.softmax(outputs, dim=1).cpu().numpy()\n",
        "    y_true_bin = label_binarize(labels, classes=np.unique(labels))\n",
        "\n",
        "    # Вычисляем Confusion Matrix\n",
        "    cm = confusion_matrix(labels, preds)\n",
        "\n",
        "    return {\n",
        "        'accuracy': accuracy_score(labels, preds),\n",
        "        'precision': precision_score(labels, preds, average='weighted'),\n",
        "        'recall': recall_score(labels, preds, average='weighted'),\n",
        "        'f1': f1_score(labels, preds, average='weighted'),\n",
        "        'auroc': roc_auc_score(y_true_bin, probs, multi_class='ovr', average='weighted'),\n",
        "        'confusion_matrix': cm  # Возвращаем матрицу для дальнейшего анализа\n",
        "    }\n",
        "\n",
        "def multiclass_training_with_cv(X_train, Y_train, X_test, Y_test, n_splits=5, num_epochs=300, patience=30):\n",
        "    input_size = X_train.shape[2]\n",
        "    kf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
        "    fold_metrics = []\n",
        "    fold_epochs = []\n",
        "\n",
        "    for fold, (train_idx, val_idx) in enumerate(kf.split(X_train, Y_train.argmax(dim=1))):  # Используем argmax для стратификации\n",
        "        print(f\"\\n--- Fold {fold + 1}/{n_splits} ---\")\n",
        "\n",
        "        # Split data\n",
        "        X_fold_train, X_fold_val = X_train[train_idx], X_train[val_idx]\n",
        "        Y_fold_train, Y_fold_val = Y_train[train_idx], Y_train[val_idx]\n",
        "\n",
        "        # Train with early stopping per fold\n",
        "        model, train_loss, val_loss, epoch = multiclass_train_model(\n",
        "            X_fold_train, Y_fold_train,\n",
        "            X_fold_val, Y_fold_val,\n",
        "            input_size,\n",
        "            num_epochs=num_epochs,\n",
        "            patience=patience\n",
        "        )\n",
        "\n",
        "        # Evaluate on test set (optional per fold)\n",
        "        class_names = ['Baseline', 'Stress', 'Amusement']\n",
        "        fold_test_metrics = multiclass_evaluate(model, X_test, Y_test, plot_cm=True, class_names=class_names)\n",
        "        fold_metrics.append(fold_test_metrics)\n",
        "        fold_epochs.append(epoch)\n",
        "        print(f\"Fold {fold + 1} Test Metrics:\", fold_test_metrics)\n",
        "\n",
        "    return fold_metrics, fold_epochs\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "7mhNHfTLfIXW"
      },
      "outputs": [],
      "source": [
        "def run_multiclass_experiment(path, window, timestep):\n",
        "    ans = data_processing_multiclass(path, window, timestep)\n",
        "\n",
        "    if not ans:\n",
        "      return None\n",
        "\n",
        "    X_train, Y_train, X_test, Y_test = ans\n",
        "\n",
        "    with open(log_file, \"a\") as f:\n",
        "        f.write(f\"\\n=== Window: {window}, Timestep: {timestep} ===\\n\")\n",
        "\n",
        "    print(f\"\\nProcessing window={window}, timestep={timestep}\")\n",
        "    start_time = time.time()\n",
        "\n",
        "    try:\n",
        "      metrics, epochs = multiclass_training_with_cv(X_train, Y_train, X_test, Y_test, n_splits=10)\n",
        "\n",
        "      elapsed = time.time() - start_time\n",
        "\n",
        "      with open(log_file, \"a\") as f:\n",
        "        f.write(f\"Time: {elapsed:.2f} sec\\n\")\n",
        "        f.write(f\"Epochs: {', '.join(map(str, epochs))}\")\n",
        "        f.write(f\"Metrics: {metrics}\\n\")\n",
        "        print(f\"Class distribution (train): {np.unique(Y_train.argmax(dim=1), return_counts=True)}\")\n",
        "        print(f\"Class distribution (test): {np.unique(Y_test.argmax(dim=1), return_counts=True)}\")\n",
        "\n",
        "        print(\"Final Test Metrics:\", metrics)\n",
        "        print(\"Final epoch's number\")\n",
        "\n",
        "    except Exception as e:\n",
        "      with open(log_file, \"a\") as f:\n",
        "          f.write(f\"Error: {str(e)}\\n\")\n",
        "          print(f\"Error for window={window}, timestep={timestep}: {str(e)}\\n\")\n",
        "          traceback.print_exc()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Wy64NVM7Lfe"
      },
      "source": [
        "###4 скрытых LSTM-слоя"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xm3Y9PyqpLOM"
      },
      "outputs": [],
      "source": [
        "# Основной цикл обучения остается таким же, но теперь работает с 3 классами\n",
        "!mkdir -p /content/drive/MyDrive/Thesis/Results\n",
        "all_steps = None\n",
        "all_results = None\n",
        "log_file = \"/content/drive/MyDrive/Thesis/Results/multiclass_log_v1_4h.txt\"\n",
        "\n",
        "with open(log_file, \"a\") as f:\n",
        "    f.write(\"Training Log - \" + datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\") + \"\\n\\n\")\n",
        "\n",
        "#run_multiclass_experiment(path, 0, 1)\n",
        "\n",
        "for window in range(15, 46, 15):\n",
        "    for timestep in range(2, 9):\n",
        "      if window == 15 or window == 30 or window == 45 and timestep < 8:\n",
        "        continue\n",
        "      run_multiclass_experiment(path, window, timestep)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_wwLmGNkFhwA",
        "outputId": "3ff4de10-9c8c-4e04-ea15-8ca0075c7e69"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Processing window=15, timestep=8\n",
            "\n",
            "--- Fold 1/10 ---\n",
            "Epoch [10/300], Train Loss: 0.8287, Val Loss: 0.7717\n",
            "Epoch [20/300], Train Loss: 0.7575, Val Loss: 0.6974\n",
            "Epoch [30/300], Train Loss: 0.7337, Val Loss: 0.6843\n",
            "Epoch [40/300], Train Loss: 0.6992, Val Loss: 0.6480\n",
            "Epoch [50/300], Train Loss: 0.6636, Val Loss: 0.6122\n",
            "Epoch [60/300], Train Loss: 0.6322, Val Loss: 0.5860\n",
            "Epoch [70/300], Train Loss: 0.6256, Val Loss: 0.5731\n",
            "Epoch [80/300], Train Loss: 0.5881, Val Loss: 0.5294\n",
            "Epoch [90/300], Train Loss: 0.6341, Val Loss: 0.6975\n",
            "Epoch [100/300], Train Loss: 0.5978, Val Loss: 0.5515\n",
            "Epoch [110/300], Train Loss: 0.5942, Val Loss: 0.5488\n",
            "Early stopping at epoch 115 (no improvement for 30 epochs)\n",
            "Fold 1 Test Metrics: {'accuracy': 0.7253218884120172, 'precision': 0.7330957136145896, 'recall': 0.7253218884120172, 'f1': 0.7277195562292134, 'auroc': np.float64(0.9002392813710375), 'confusion_matrix': array([[163,   6,  58],\n",
            "       [ 19, 194,  20],\n",
            "       [ 75,  14, 150]])}\n",
            "\n",
            "--- Fold 2/10 ---\n",
            "Epoch [10/300], Train Loss: 0.8971, Val Loss: 0.8445\n",
            "Epoch [20/300], Train Loss: 0.7712, Val Loss: 0.7477\n",
            "Epoch [30/300], Train Loss: 0.7434, Val Loss: 0.7290\n",
            "Epoch [40/300], Train Loss: 0.7124, Val Loss: 0.7069\n",
            "Epoch [50/300], Train Loss: 0.6833, Val Loss: 0.6820\n",
            "Epoch [60/300], Train Loss: 0.6852, Val Loss: 0.6839\n",
            "Epoch [70/300], Train Loss: 0.6925, Val Loss: 0.6943\n",
            "Epoch [80/300], Train Loss: 0.6334, Val Loss: 0.6360\n",
            "Epoch [90/300], Train Loss: 0.6024, Val Loss: 0.6119\n",
            "Epoch [100/300], Train Loss: 0.5927, Val Loss: 0.5881\n",
            "Epoch [110/300], Train Loss: 0.6632, Val Loss: 0.6952\n",
            "Epoch [120/300], Train Loss: 0.6076, Val Loss: 0.6076\n",
            "Epoch [130/300], Train Loss: 0.5842, Val Loss: 0.5912\n",
            "Early stopping at epoch 134 (no improvement for 30 epochs)\n",
            "Fold 2 Test Metrics: {'accuracy': 0.7367668097281831, 'precision': 0.7365472520885112, 'recall': 0.7367668097281831, 'f1': 0.7346660662557603, 'auroc': np.float64(0.8981666231234904), 'confusion_matrix': array([[161,  17,  49],\n",
            "       [ 11, 210,  12],\n",
            "       [ 79,  16, 144]])}\n",
            "\n",
            "--- Fold 3/10 ---\n",
            "Epoch [10/300], Train Loss: 0.8588, Val Loss: 0.8536\n",
            "Epoch [20/300], Train Loss: 0.7646, Val Loss: 0.7815\n",
            "Epoch [30/300], Train Loss: 0.7239, Val Loss: 0.7609\n",
            "Epoch [40/300], Train Loss: 0.6831, Val Loss: 0.7187\n",
            "Epoch [50/300], Train Loss: 0.6528, Val Loss: 0.6926\n",
            "Epoch [60/300], Train Loss: 0.6207, Val Loss: 0.6449\n",
            "Epoch [70/300], Train Loss: 0.7650, Val Loss: 0.6528\n",
            "Epoch [80/300], Train Loss: 0.6222, Val Loss: 0.6424\n",
            "Epoch [90/300], Train Loss: 0.6154, Val Loss: 0.6352\n",
            "Early stopping at epoch 96 (no improvement for 30 epochs)\n",
            "Fold 3 Test Metrics: {'accuracy': 0.7224606580829757, 'precision': 0.745626771051578, 'recall': 0.7224606580829757, 'f1': 0.7282836794359562, 'auroc': np.float64(0.8922117823495994), 'confusion_matrix': array([[171,   1,  55],\n",
            "       [ 22, 176,  35],\n",
            "       [ 75,   6, 158]])}\n",
            "\n",
            "--- Fold 4/10 ---\n",
            "Epoch [10/300], Train Loss: 0.8239, Val Loss: 0.8155\n",
            "Epoch [20/300], Train Loss: 0.7596, Val Loss: 0.7454\n",
            "Epoch [30/300], Train Loss: 0.7388, Val Loss: 0.7191\n",
            "Epoch [40/300], Train Loss: 0.6929, Val Loss: 0.6861\n",
            "Epoch [50/300], Train Loss: 0.6607, Val Loss: 0.6547\n",
            "Epoch [60/300], Train Loss: 0.6363, Val Loss: 0.6265\n",
            "Epoch [70/300], Train Loss: 0.6160, Val Loss: 0.6216\n",
            "Epoch [80/300], Train Loss: 0.6325, Val Loss: 0.6127\n",
            "Epoch [90/300], Train Loss: 0.5908, Val Loss: 0.5878\n",
            "Epoch [100/300], Train Loss: 0.5810, Val Loss: 0.5881\n",
            "Epoch [110/300], Train Loss: 0.5783, Val Loss: 0.5822\n",
            "Epoch [120/300], Train Loss: 0.5770, Val Loss: 0.5810\n",
            "Epoch [130/300], Train Loss: 0.5765, Val Loss: 0.5812\n",
            "Epoch [140/300], Train Loss: 0.5765, Val Loss: 0.5812\n",
            "Early stopping at epoch 149 (no improvement for 30 epochs)\n",
            "Fold 4 Test Metrics: {'accuracy': 0.7367668097281831, 'precision': 0.7544645912322868, 'recall': 0.7367668097281831, 'f1': 0.7418776157141541, 'auroc': np.float64(0.8984069909812754), 'confusion_matrix': array([[170,   2,  55],\n",
            "       [ 19, 188,  26],\n",
            "       [ 77,   5, 157]])}\n",
            "\n",
            "--- Fold 5/10 ---\n",
            "Epoch [10/300], Train Loss: 0.8121, Val Loss: 0.8044\n",
            "Epoch [20/300], Train Loss: 0.7573, Val Loss: 0.7838\n",
            "Epoch [30/300], Train Loss: 0.7109, Val Loss: 0.7350\n",
            "Epoch [40/300], Train Loss: 0.6755, Val Loss: 0.7045\n",
            "Epoch [50/300], Train Loss: 0.6520, Val Loss: 0.6885\n",
            "Epoch [60/300], Train Loss: 0.6184, Val Loss: 0.6480\n",
            "Epoch [70/300], Train Loss: 0.6080, Val Loss: 0.6604\n",
            "Epoch [80/300], Train Loss: 0.5685, Val Loss: 0.6212\n",
            "Epoch [90/300], Train Loss: 0.5649, Val Loss: 0.6174\n",
            "Epoch [100/300], Train Loss: 0.5612, Val Loss: 0.6143\n",
            "Epoch [110/300], Train Loss: 0.5573, Val Loss: 0.6105\n",
            "Epoch [120/300], Train Loss: 0.5533, Val Loss: 0.6071\n",
            "Epoch [130/300], Train Loss: 0.5482, Val Loss: 0.6024\n",
            "Epoch [140/300], Train Loss: 0.5438, Val Loss: 0.5976\n",
            "Epoch [150/300], Train Loss: 0.5393, Val Loss: 0.5924\n",
            "Epoch [160/300], Train Loss: 0.5344, Val Loss: 0.5863\n",
            "Epoch [170/300], Train Loss: 0.5295, Val Loss: 0.5804\n",
            "Epoch [180/300], Train Loss: 0.5247, Val Loss: 0.5754\n",
            "Epoch [190/300], Train Loss: 0.5201, Val Loss: 0.5707\n",
            "Epoch [200/300], Train Loss: 0.5157, Val Loss: 0.5662\n",
            "Epoch [210/300], Train Loss: 0.5113, Val Loss: 0.5617\n",
            "Epoch [220/300], Train Loss: 0.5065, Val Loss: 0.5571\n",
            "Epoch [230/300], Train Loss: 0.5014, Val Loss: 0.5535\n",
            "Epoch [240/300], Train Loss: 0.4963, Val Loss: 0.5468\n",
            "Epoch [250/300], Train Loss: 0.4916, Val Loss: 0.5413\n",
            "Epoch [260/300], Train Loss: 0.4867, Val Loss: 0.5373\n",
            "Epoch [270/300], Train Loss: 0.4815, Val Loss: 0.5314\n",
            "Epoch [280/300], Train Loss: 0.4761, Val Loss: 0.5253\n",
            "Epoch [290/300], Train Loss: 0.4706, Val Loss: 0.5184\n",
            "Epoch [300/300], Train Loss: 0.4648, Val Loss: 0.5116\n",
            "Fold 5 Test Metrics: {'accuracy': 0.7896995708154506, 'precision': 0.7970674296693123, 'recall': 0.7896995708154506, 'f1': 0.7924235773319036, 'auroc': np.float64(0.9385063558897847), 'confusion_matrix': array([[171,   1,  55],\n",
            "       [ 18, 203,  12],\n",
            "       [ 53,   8, 178]])}\n",
            "\n",
            "--- Fold 6/10 ---\n",
            "Epoch [10/300], Train Loss: 0.8283, Val Loss: 0.8489\n",
            "Epoch [20/300], Train Loss: 0.7527, Val Loss: 0.8180\n",
            "Epoch [30/300], Train Loss: 0.7419, Val Loss: 0.8006\n",
            "Epoch [40/300], Train Loss: 0.7357, Val Loss: 0.7980\n",
            "Epoch [50/300], Train Loss: 0.7297, Val Loss: 0.7899\n",
            "Epoch [60/300], Train Loss: 0.7240, Val Loss: 0.7838\n",
            "Epoch [70/300], Train Loss: 0.7181, Val Loss: 0.7756\n",
            "Epoch [80/300], Train Loss: 0.7123, Val Loss: 0.7685\n",
            "Epoch [90/300], Train Loss: 0.7068, Val Loss: 0.7614\n",
            "Epoch [100/300], Train Loss: 0.7014, Val Loss: 0.7529\n",
            "Epoch [110/300], Train Loss: 0.6954, Val Loss: 0.7438\n",
            "Epoch [120/300], Train Loss: 0.6872, Val Loss: 0.7276\n",
            "Epoch [130/300], Train Loss: 0.6772, Val Loss: 0.7205\n",
            "Epoch [140/300], Train Loss: 0.6706, Val Loss: 0.7092\n",
            "Epoch [150/300], Train Loss: 0.6639, Val Loss: 0.7023\n",
            "Epoch [160/300], Train Loss: 0.6567, Val Loss: 0.6952\n",
            "Epoch [170/300], Train Loss: 0.6491, Val Loss: 0.6859\n",
            "Epoch [180/300], Train Loss: 0.6418, Val Loss: 0.6803\n",
            "Epoch [190/300], Train Loss: 0.6370, Val Loss: 0.6749\n",
            "Epoch [200/300], Train Loss: 0.6333, Val Loss: 0.6688\n",
            "Epoch [210/300], Train Loss: 0.6332, Val Loss: 0.6694\n",
            "Epoch [220/300], Train Loss: 0.6330, Val Loss: 0.6692\n",
            "Early stopping at epoch 229 (no improvement for 30 epochs)\n",
            "Fold 6 Test Metrics: {'accuracy': 0.6952789699570815, 'precision': 0.7108428946517373, 'recall': 0.6952789699570815, 'f1': 0.7006763150894552, 'auroc': np.float64(0.8626794824639092), 'confusion_matrix': array([[139,   8,  80],\n",
            "       [  8, 189,  36],\n",
            "       [ 75,   6, 158]])}\n",
            "\n",
            "--- Fold 7/10 ---\n",
            "Epoch [10/300], Train Loss: 0.8892, Val Loss: 0.8638\n",
            "Epoch [20/300], Train Loss: 0.7685, Val Loss: 0.7734\n",
            "Epoch [30/300], Train Loss: 0.7590, Val Loss: 0.7603\n",
            "Epoch [40/300], Train Loss: 0.7428, Val Loss: 0.7431\n",
            "Epoch [50/300], Train Loss: 0.7365, Val Loss: 0.7284\n",
            "Epoch [60/300], Train Loss: 0.7315, Val Loss: 0.7243\n",
            "Epoch [70/300], Train Loss: 0.7268, Val Loss: 0.7233\n",
            "Epoch [80/300], Train Loss: 0.7264, Val Loss: 0.7231\n",
            "Epoch [90/300], Train Loss: 0.7264, Val Loss: 0.7230\n",
            "Early stopping at epoch 91 (no improvement for 30 epochs)\n",
            "Fold 7 Test Metrics: {'accuracy': 0.6337625178826896, 'precision': 0.644451290620205, 'recall': 0.6337625178826896, 'f1': 0.6373093713209282, 'auroc': np.float64(0.8207258369227213), 'confusion_matrix': array([[138,  18,  71],\n",
            "       [ 15, 185,  33],\n",
            "       [110,   9, 120]])}\n",
            "\n",
            "--- Fold 8/10 ---\n",
            "Epoch [10/300], Train Loss: 0.8599, Val Loss: 0.8649\n",
            "Epoch [20/300], Train Loss: 0.7601, Val Loss: 0.7392\n",
            "Epoch [30/300], Train Loss: 0.7358, Val Loss: 0.7057\n",
            "Epoch [40/300], Train Loss: 0.7123, Val Loss: 0.6876\n",
            "Epoch [50/300], Train Loss: 0.6922, Val Loss: 0.6680\n",
            "Epoch [60/300], Train Loss: 0.6910, Val Loss: 0.6868\n",
            "Epoch [70/300], Train Loss: 0.6549, Val Loss: 0.6469\n",
            "Epoch [80/300], Train Loss: 0.6535, Val Loss: 0.6442\n",
            "Epoch [90/300], Train Loss: 0.6521, Val Loss: 0.6428\n",
            "Epoch [100/300], Train Loss: 0.6503, Val Loss: 0.6410\n",
            "Epoch [110/300], Train Loss: 0.6485, Val Loss: 0.6393\n",
            "Epoch [120/300], Train Loss: 0.6467, Val Loss: 0.6376\n",
            "Epoch [130/300], Train Loss: 0.6450, Val Loss: 0.6360\n",
            "Epoch [140/300], Train Loss: 0.6436, Val Loss: 0.6347\n",
            "Epoch [150/300], Train Loss: 0.6430, Val Loss: 0.6338\n",
            "Epoch [160/300], Train Loss: 0.6427, Val Loss: 0.6334\n",
            "Epoch [170/300], Train Loss: 0.6424, Val Loss: 0.6333\n",
            "Epoch [180/300], Train Loss: 0.6423, Val Loss: 0.6332\n",
            "Epoch [190/300], Train Loss: 0.6423, Val Loss: 0.6332\n",
            "Epoch [200/300], Train Loss: 0.6423, Val Loss: 0.6332\n",
            "Epoch [210/300], Train Loss: 0.6422, Val Loss: 0.6332\n",
            "Epoch [220/300], Train Loss: 0.6422, Val Loss: 0.6332\n",
            "Epoch [230/300], Train Loss: 0.6422, Val Loss: 0.6332\n",
            "Epoch [240/300], Train Loss: 0.6422, Val Loss: 0.6332\n",
            "Epoch [250/300], Train Loss: 0.6421, Val Loss: 0.6332\n",
            "Epoch [260/300], Train Loss: 0.6421, Val Loss: 0.6332\n",
            "Epoch [270/300], Train Loss: 0.6421, Val Loss: 0.6332\n",
            "Epoch [280/300], Train Loss: 0.6421, Val Loss: 0.6332\n",
            "Epoch [290/300], Train Loss: 0.6421, Val Loss: 0.6332\n",
            "Epoch [300/300], Train Loss: 0.6420, Val Loss: 0.6332\n",
            "Fold 8 Test Metrics: {'accuracy': 0.6866952789699571, 'precision': 0.6953211163556754, 'recall': 0.6866952789699571, 'f1': 0.6899581589894778, 'auroc': np.float64(0.8613545398714709), 'confusion_matrix': array([[148,  13,  66],\n",
            "       [ 15, 190,  28],\n",
            "       [ 87,  10, 142]])}\n",
            "\n",
            "--- Fold 9/10 ---\n",
            "Epoch [10/300], Train Loss: 0.8559, Val Loss: 0.8299\n",
            "Epoch [20/300], Train Loss: 0.7594, Val Loss: 0.7341\n",
            "Epoch [30/300], Train Loss: 0.7226, Val Loss: 0.7006\n",
            "Epoch [40/300], Train Loss: 0.6978, Val Loss: 0.6871\n",
            "Epoch [50/300], Train Loss: 0.6617, Val Loss: 0.6636\n",
            "Epoch [60/300], Train Loss: 0.6346, Val Loss: 0.6389\n",
            "Epoch [70/300], Train Loss: 0.6263, Val Loss: 0.6726\n",
            "Epoch [80/300], Train Loss: 0.7206, Val Loss: 0.6936\n",
            "Epoch [90/300], Train Loss: 0.6383, Val Loss: 0.6594\n",
            "Epoch [100/300], Train Loss: 0.6356, Val Loss: 0.6565\n",
            "Early stopping at epoch 101 (no improvement for 30 epochs)\n",
            "Fold 9 Test Metrics: {'accuracy': 0.7067238912732475, 'precision': 0.71876267083273, 'recall': 0.7067238912732475, 'f1': 0.7040641727966499, 'auroc': np.float64(0.8826748076637926), 'confusion_matrix': array([[175,  14,  38],\n",
            "       [ 22, 196,  15],\n",
            "       [ 99,  17, 123]])}\n",
            "\n",
            "--- Fold 10/10 ---\n",
            "Epoch [10/300], Train Loss: 0.8325, Val Loss: 0.8065\n",
            "Epoch [20/300], Train Loss: 0.7528, Val Loss: 0.7547\n",
            "Epoch [30/300], Train Loss: 0.7098, Val Loss: 0.7057\n",
            "Epoch [40/300], Train Loss: 0.6755, Val Loss: 0.6741\n",
            "Epoch [50/300], Train Loss: 0.6521, Val Loss: 0.6546\n",
            "Epoch [60/300], Train Loss: 0.6376, Val Loss: 0.6406\n",
            "Epoch [70/300], Train Loss: 0.6049, Val Loss: 0.6052\n",
            "Epoch [80/300], Train Loss: 0.5959, Val Loss: 0.6039\n",
            "Epoch [90/300], Train Loss: 0.5941, Val Loss: 0.6001\n",
            "Epoch [100/300], Train Loss: 0.5934, Val Loss: 0.5991\n",
            "Epoch [110/300], Train Loss: 0.5926, Val Loss: 0.5987\n",
            "Epoch [120/300], Train Loss: 0.5919, Val Loss: 0.5983\n",
            "Epoch [130/300], Train Loss: 0.5913, Val Loss: 0.5978\n",
            "Epoch [140/300], Train Loss: 0.5906, Val Loss: 0.5972\n",
            "Epoch [150/300], Train Loss: 0.5900, Val Loss: 0.5966\n",
            "Epoch [160/300], Train Loss: 0.5894, Val Loss: 0.5961\n",
            "Epoch [170/300], Train Loss: 0.5888, Val Loss: 0.5955\n",
            "Epoch [180/300], Train Loss: 0.5882, Val Loss: 0.5950\n",
            "Epoch [190/300], Train Loss: 0.5876, Val Loss: 0.5944\n",
            "Epoch [200/300], Train Loss: 0.5870, Val Loss: 0.5938\n",
            "Epoch [210/300], Train Loss: 0.5864, Val Loss: 0.5933\n",
            "Epoch [220/300], Train Loss: 0.5858, Val Loss: 0.5927\n",
            "Epoch [230/300], Train Loss: 0.5851, Val Loss: 0.5921\n",
            "Epoch [240/300], Train Loss: 0.5845, Val Loss: 0.5915\n",
            "Epoch [250/300], Train Loss: 0.5838, Val Loss: 0.5908\n",
            "Epoch [260/300], Train Loss: 0.5831, Val Loss: 0.5902\n",
            "Epoch [270/300], Train Loss: 0.5825, Val Loss: 0.5896\n",
            "Epoch [280/300], Train Loss: 0.5818, Val Loss: 0.5890\n",
            "Epoch [290/300], Train Loss: 0.5811, Val Loss: 0.5884\n",
            "Epoch [300/300], Train Loss: 0.5804, Val Loss: 0.5877\n",
            "Fold 10 Test Metrics: {'accuracy': 0.7324749642346209, 'precision': 0.742592248577198, 'recall': 0.7324749642346209, 'f1': 0.7357680605896353, 'auroc': np.float64(0.8968420970270651), 'confusion_matrix': array([[165,   7,  55],\n",
            "       [ 18, 190,  25],\n",
            "       [ 72,  10, 157]])}\n",
            "Class distribution (train): (array([0, 1, 2]), array([1297, 1285, 1331]))\n",
            "Class distribution (test): (array([0, 1, 2]), array([227, 233, 239]))\n",
            "Final Test Metrics: [{'accuracy': 0.7253218884120172, 'precision': 0.7330957136145896, 'recall': 0.7253218884120172, 'f1': 0.7277195562292134, 'auroc': np.float64(0.9002392813710375), 'confusion_matrix': array([[163,   6,  58],\n",
            "       [ 19, 194,  20],\n",
            "       [ 75,  14, 150]])}, {'accuracy': 0.7367668097281831, 'precision': 0.7365472520885112, 'recall': 0.7367668097281831, 'f1': 0.7346660662557603, 'auroc': np.float64(0.8981666231234904), 'confusion_matrix': array([[161,  17,  49],\n",
            "       [ 11, 210,  12],\n",
            "       [ 79,  16, 144]])}, {'accuracy': 0.7224606580829757, 'precision': 0.745626771051578, 'recall': 0.7224606580829757, 'f1': 0.7282836794359562, 'auroc': np.float64(0.8922117823495994), 'confusion_matrix': array([[171,   1,  55],\n",
            "       [ 22, 176,  35],\n",
            "       [ 75,   6, 158]])}, {'accuracy': 0.7367668097281831, 'precision': 0.7544645912322868, 'recall': 0.7367668097281831, 'f1': 0.7418776157141541, 'auroc': np.float64(0.8984069909812754), 'confusion_matrix': array([[170,   2,  55],\n",
            "       [ 19, 188,  26],\n",
            "       [ 77,   5, 157]])}, {'accuracy': 0.7896995708154506, 'precision': 0.7970674296693123, 'recall': 0.7896995708154506, 'f1': 0.7924235773319036, 'auroc': np.float64(0.9385063558897847), 'confusion_matrix': array([[171,   1,  55],\n",
            "       [ 18, 203,  12],\n",
            "       [ 53,   8, 178]])}, {'accuracy': 0.6952789699570815, 'precision': 0.7108428946517373, 'recall': 0.6952789699570815, 'f1': 0.7006763150894552, 'auroc': np.float64(0.8626794824639092), 'confusion_matrix': array([[139,   8,  80],\n",
            "       [  8, 189,  36],\n",
            "       [ 75,   6, 158]])}, {'accuracy': 0.6337625178826896, 'precision': 0.644451290620205, 'recall': 0.6337625178826896, 'f1': 0.6373093713209282, 'auroc': np.float64(0.8207258369227213), 'confusion_matrix': array([[138,  18,  71],\n",
            "       [ 15, 185,  33],\n",
            "       [110,   9, 120]])}, {'accuracy': 0.6866952789699571, 'precision': 0.6953211163556754, 'recall': 0.6866952789699571, 'f1': 0.6899581589894778, 'auroc': np.float64(0.8613545398714709), 'confusion_matrix': array([[148,  13,  66],\n",
            "       [ 15, 190,  28],\n",
            "       [ 87,  10, 142]])}, {'accuracy': 0.7067238912732475, 'precision': 0.71876267083273, 'recall': 0.7067238912732475, 'f1': 0.7040641727966499, 'auroc': np.float64(0.8826748076637926), 'confusion_matrix': array([[175,  14,  38],\n",
            "       [ 22, 196,  15],\n",
            "       [ 99,  17, 123]])}, {'accuracy': 0.7324749642346209, 'precision': 0.742592248577198, 'recall': 0.7324749642346209, 'f1': 0.7357680605896353, 'auroc': np.float64(0.8968420970270651), 'confusion_matrix': array([[165,   7,  55],\n",
            "       [ 18, 190,  25],\n",
            "       [ 72,  10, 157]])}]\n",
            "Final epoch's number\n",
            "\n",
            "Processing window=30, timestep=2\n",
            "\n",
            "--- Fold 1/10 ---\n",
            "Epoch [10/300], Train Loss: 0.8393, Val Loss: 0.7742\n",
            "Epoch [20/300], Train Loss: 0.7593, Val Loss: 0.7140\n",
            "Epoch [30/300], Train Loss: 0.7003, Val Loss: 0.6585\n",
            "Epoch [40/300], Train Loss: 0.6714, Val Loss: 0.6580\n",
            "Epoch [50/300], Train Loss: 0.6344, Val Loss: 0.5885\n",
            "Epoch [60/300], Train Loss: 0.6484, Val Loss: 0.5622\n",
            "Epoch [70/300], Train Loss: 0.5926, Val Loss: 0.5434\n",
            "Epoch [80/300], Train Loss: 0.5829, Val Loss: 0.5470\n",
            "Epoch [90/300], Train Loss: 0.5815, Val Loss: 0.5437\n",
            "Epoch [100/300], Train Loss: 0.5814, Val Loss: 0.5436\n",
            "Early stopping at epoch 102 (no improvement for 30 epochs)\n",
            "Fold 1 Test Metrics: {'accuracy': 0.7396280400572246, 'precision': 0.7533098431388323, 'recall': 0.7396280400572246, 'f1': 0.743941274844987, 'auroc': np.float64(0.8977619603707641), 'confusion_matrix': array([[168,   1,  58],\n",
            "       [ 18, 191,  24],\n",
            "       [ 72,   9, 158]])}\n",
            "\n",
            "--- Fold 2/10 ---\n",
            "Epoch [10/300], Train Loss: 0.8526, Val Loss: 0.8525\n",
            "Epoch [20/300], Train Loss: 0.7565, Val Loss: 0.7732\n",
            "Epoch [30/300], Train Loss: 0.7298, Val Loss: 0.7291\n",
            "Epoch [40/300], Train Loss: 0.6831, Val Loss: 0.6873\n",
            "Epoch [50/300], Train Loss: 0.6715, Val Loss: 0.6778\n",
            "Epoch [60/300], Train Loss: 0.6275, Val Loss: 0.6355\n",
            "Epoch [70/300], Train Loss: 0.5920, Val Loss: 0.6146\n",
            "Epoch [80/300], Train Loss: 0.6021, Val Loss: 0.6066\n",
            "Epoch [90/300], Train Loss: 0.5625, Val Loss: 0.5746\n",
            "Epoch [100/300], Train Loss: 0.5594, Val Loss: 0.5739\n",
            "Epoch [110/300], Train Loss: 0.5571, Val Loss: 0.5722\n",
            "Epoch [120/300], Train Loss: 0.5571, Val Loss: 0.5721\n",
            "Early stopping at epoch 124 (no improvement for 30 epochs)\n",
            "Fold 2 Test Metrics: {'accuracy': 0.7367668097281831, 'precision': 0.7464279288226718, 'recall': 0.7367668097281831, 'f1': 0.740140412433137, 'auroc': np.float64(0.9101696512463283), 'confusion_matrix': array([[163,   5,  59],\n",
            "       [ 19, 192,  22],\n",
            "       [ 68,  11, 160]])}\n",
            "\n",
            "--- Fold 3/10 ---\n",
            "Epoch [10/300], Train Loss: 0.8342, Val Loss: 0.8307\n",
            "Epoch [20/300], Train Loss: 0.7485, Val Loss: 0.7679\n",
            "Epoch [30/300], Train Loss: 0.7076, Val Loss: 0.7347\n",
            "Epoch [40/300], Train Loss: 0.6646, Val Loss: 0.7020\n",
            "Epoch [50/300], Train Loss: 0.6286, Val Loss: 0.6628\n",
            "Epoch [60/300], Train Loss: 0.5987, Val Loss: 0.6349\n",
            "Epoch [70/300], Train Loss: 0.6061, Val Loss: 0.6364\n",
            "Epoch [80/300], Train Loss: 0.5944, Val Loss: 0.6315\n",
            "Early stopping at epoch 88 (no improvement for 30 epochs)\n",
            "Fold 3 Test Metrics: {'accuracy': 0.6952789699570815, 'precision': 0.7319324049414602, 'recall': 0.6952789699570815, 'f1': 0.6959010118114961, 'auroc': np.float64(0.882430520874891), 'confusion_matrix': array([[108,   6, 113],\n",
            "       [  3, 186,  44],\n",
            "       [ 40,   7, 192]])}\n",
            "\n",
            "--- Fold 4/10 ---\n",
            "Epoch [10/300], Train Loss: 0.8284, Val Loss: 0.8132\n",
            "Epoch [20/300], Train Loss: 0.7487, Val Loss: 0.7387\n",
            "Epoch [30/300], Train Loss: 0.7148, Val Loss: 0.6947\n",
            "Epoch [40/300], Train Loss: 0.6951, Val Loss: 0.6849\n",
            "Epoch [50/300], Train Loss: 0.6571, Val Loss: 0.6646\n",
            "Epoch [60/300], Train Loss: 0.6633, Val Loss: 0.6164\n",
            "Epoch [70/300], Train Loss: 0.6178, Val Loss: 0.6147\n",
            "Epoch [80/300], Train Loss: 0.6124, Val Loss: 0.6060\n",
            "Epoch [90/300], Train Loss: 0.6069, Val Loss: 0.5997\n",
            "Epoch [100/300], Train Loss: 0.6041, Val Loss: 0.5993\n",
            "Epoch [110/300], Train Loss: 0.6031, Val Loss: 0.5981\n",
            "Epoch [120/300], Train Loss: 0.6028, Val Loss: 0.5981\n",
            "Epoch [130/300], Train Loss: 0.6028, Val Loss: 0.5981\n",
            "Epoch [140/300], Train Loss: 0.6028, Val Loss: 0.5981\n",
            "Early stopping at epoch 142 (no improvement for 30 epochs)\n",
            "Fold 4 Test Metrics: {'accuracy': 0.7010014306151645, 'precision': 0.7117961536148878, 'recall': 0.7010014306151645, 'f1': 0.7052711802494667, 'auroc': np.float64(0.8780759285941498), 'confusion_matrix': array([[148,   3,  76],\n",
            "       [ 13, 192,  28],\n",
            "       [ 75,  14, 150]])}\n",
            "\n",
            "--- Fold 5/10 ---\n",
            "Epoch [10/300], Train Loss: 0.8627, Val Loss: 0.8588\n",
            "Epoch [20/300], Train Loss: 0.7450, Val Loss: 0.7646\n",
            "Epoch [30/300], Train Loss: 0.7120, Val Loss: 0.7372\n",
            "Epoch [40/300], Train Loss: 0.6757, Val Loss: 0.7062\n",
            "Epoch [50/300], Train Loss: 0.6480, Val Loss: 0.6845\n",
            "Epoch [60/300], Train Loss: 0.6221, Val Loss: 0.6638\n",
            "Epoch [70/300], Train Loss: 0.6199, Val Loss: 0.6582\n",
            "Epoch [80/300], Train Loss: 0.6272, Val Loss: 0.6451\n",
            "Epoch [90/300], Train Loss: 0.5829, Val Loss: 0.6299\n",
            "Epoch [100/300], Train Loss: 0.5748, Val Loss: 0.6223\n",
            "Epoch [110/300], Train Loss: 0.5746, Val Loss: 0.6220\n",
            "Early stopping at epoch 117 (no improvement for 30 epochs)\n",
            "Fold 5 Test Metrics: {'accuracy': 0.7410586552217453, 'precision': 0.7519460121452346, 'recall': 0.7410586552217453, 'f1': 0.7443078741935628, 'auroc': np.float64(0.8976742216735847), 'confusion_matrix': array([[168,   7,  52],\n",
            "       [ 20, 193,  20],\n",
            "       [ 74,   8, 157]])}\n",
            "\n",
            "--- Fold 6/10 ---\n",
            "Epoch [10/300], Train Loss: 0.9093, Val Loss: 0.9047\n",
            "Epoch [20/300], Train Loss: 0.7725, Val Loss: 0.8087\n",
            "Epoch [30/300], Train Loss: 0.7362, Val Loss: 0.7851\n",
            "Epoch [40/300], Train Loss: 0.7161, Val Loss: 0.7519\n",
            "Epoch [50/300], Train Loss: 0.6840, Val Loss: 0.7085\n",
            "Epoch [60/300], Train Loss: 0.7527, Val Loss: 0.7337\n",
            "Epoch [70/300], Train Loss: 0.6687, Val Loss: 0.6831\n",
            "Epoch [80/300], Train Loss: 0.6629, Val Loss: 0.6837\n",
            "Epoch [90/300], Train Loss: 0.6627, Val Loss: 0.6834\n",
            "Early stopping at epoch 97 (no improvement for 30 epochs)\n",
            "Fold 6 Test Metrics: {'accuracy': 0.6752503576537912, 'precision': 0.6907352956760051, 'recall': 0.6752503576537912, 'f1': 0.6794144251404286, 'auroc': np.float64(0.8499219618591998), 'confusion_matrix': array([[123,  11,  93],\n",
            "       [  7, 189,  37],\n",
            "       [ 72,   7, 160]])}\n",
            "\n",
            "--- Fold 7/10 ---\n",
            "Epoch [10/300], Train Loss: 0.8280, Val Loss: 0.8206\n",
            "Epoch [20/300], Train Loss: 0.7486, Val Loss: 0.7454\n",
            "Epoch [30/300], Train Loss: 0.7219, Val Loss: 0.7128\n",
            "Epoch [40/300], Train Loss: 0.6874, Val Loss: 0.7055\n",
            "Epoch [50/300], Train Loss: 0.6740, Val Loss: 0.6812\n",
            "Epoch [60/300], Train Loss: 0.6564, Val Loss: 0.6612\n",
            "Epoch [70/300], Train Loss: 0.6514, Val Loss: 0.6562\n",
            "Epoch [80/300], Train Loss: 0.6478, Val Loss: 0.6545\n",
            "Epoch [90/300], Train Loss: 0.6464, Val Loss: 0.6546\n",
            "Epoch [100/300], Train Loss: 0.6464, Val Loss: 0.6546\n",
            "Epoch [110/300], Train Loss: 0.6464, Val Loss: 0.6546\n",
            "Early stopping at epoch 111 (no improvement for 30 epochs)\n",
            "Fold 7 Test Metrics: {'accuracy': 0.6967095851216023, 'precision': 0.7084711643397965, 'recall': 0.6967095851216023, 'f1': 0.7009857155243422, 'auroc': np.float64(0.8639718068125074), 'confusion_matrix': array([[151,  11,  65],\n",
            "       [ 17, 189,  27],\n",
            "       [ 85,   7, 147]])}\n",
            "\n",
            "--- Fold 8/10 ---\n",
            "Epoch [10/300], Train Loss: 0.8485, Val Loss: 0.8166\n",
            "Epoch [20/300], Train Loss: 0.7521, Val Loss: 0.7266\n",
            "Epoch [30/300], Train Loss: 0.7255, Val Loss: 0.7063\n",
            "Epoch [40/300], Train Loss: 0.6942, Val Loss: 0.6671\n",
            "Epoch [50/300], Train Loss: 0.6653, Val Loss: 0.6568\n",
            "Epoch [60/300], Train Loss: 0.6454, Val Loss: 0.6203\n",
            "Epoch [70/300], Train Loss: 0.6249, Val Loss: 0.6004\n",
            "Epoch [80/300], Train Loss: 0.6195, Val Loss: 0.5848\n",
            "Epoch [90/300], Train Loss: 0.5786, Val Loss: 0.5713\n",
            "Epoch [100/300], Train Loss: 0.5630, Val Loss: 0.5591\n",
            "Epoch [110/300], Train Loss: 0.5490, Val Loss: 0.5483\n",
            "Epoch [120/300], Train Loss: 0.5469, Val Loss: 0.5425\n",
            "Epoch [130/300], Train Loss: 0.5467, Val Loss: 0.5421\n",
            "Early stopping at epoch 134 (no improvement for 30 epochs)\n",
            "Fold 8 Test Metrics: {'accuracy': 0.7424892703862661, 'precision': 0.7535562348285011, 'recall': 0.7424892703862661, 'f1': 0.7466460270333982, 'auroc': np.float64(0.9081128456379037), 'confusion_matrix': array([[158,   1,  68],\n",
            "       [ 15, 197,  21],\n",
            "       [ 66,   9, 164]])}\n",
            "\n",
            "--- Fold 9/10 ---\n",
            "Epoch [10/300], Train Loss: 0.8441, Val Loss: 0.7856\n",
            "Epoch [20/300], Train Loss: 0.7457, Val Loss: 0.7377\n",
            "Epoch [30/300], Train Loss: 0.7204, Val Loss: 0.7128\n",
            "Epoch [40/300], Train Loss: 0.6795, Val Loss: 0.6797\n",
            "Epoch [50/300], Train Loss: 0.6492, Val Loss: 0.6543\n",
            "Epoch [60/300], Train Loss: 0.6251, Val Loss: 0.6344\n",
            "Epoch [70/300], Train Loss: 0.6037, Val Loss: 0.6172\n",
            "Epoch [80/300], Train Loss: 0.5890, Val Loss: 0.5899\n",
            "Epoch [90/300], Train Loss: 0.5891, Val Loss: 0.5904\n",
            "Epoch [100/300], Train Loss: 0.5507, Val Loss: 0.5657\n",
            "Epoch [110/300], Train Loss: 0.5389, Val Loss: 0.5604\n",
            "Epoch [120/300], Train Loss: 0.5388, Val Loss: 0.5601\n",
            "Early stopping at epoch 127 (no improvement for 30 epochs)\n",
            "Fold 9 Test Metrics: {'accuracy': 0.7439198855507868, 'precision': 0.7591494734678985, 'recall': 0.7439198855507868, 'f1': 0.7490050399250213, 'auroc': np.float64(0.9089796160335698), 'confusion_matrix': array([[163,   1,  63],\n",
            "       [ 21, 192,  20],\n",
            "       [ 68,   6, 165]])}\n",
            "\n",
            "--- Fold 10/10 ---\n",
            "Epoch [10/300], Train Loss: 0.8458, Val Loss: 0.8163\n",
            "Epoch [20/300], Train Loss: 0.7534, Val Loss: 0.7498\n",
            "Epoch [30/300], Train Loss: 0.7283, Val Loss: 0.7207\n",
            "Epoch [40/300], Train Loss: 0.6855, Val Loss: 0.6741\n",
            "Epoch [50/300], Train Loss: 0.6472, Val Loss: 0.6403\n",
            "Epoch [60/300], Train Loss: 0.6143, Val Loss: 0.6205\n",
            "Epoch [70/300], Train Loss: 0.5937, Val Loss: 0.6032\n",
            "Epoch [80/300], Train Loss: 0.5798, Val Loss: 0.6114\n",
            "Epoch [90/300], Train Loss: 0.5855, Val Loss: 0.5783\n",
            "Epoch [100/300], Train Loss: 0.5487, Val Loss: 0.5655\n",
            "Epoch [110/300], Train Loss: 0.5384, Val Loss: 0.5553\n",
            "Epoch [120/300], Train Loss: 0.5344, Val Loss: 0.5520\n",
            "Epoch [130/300], Train Loss: 0.5324, Val Loss: 0.5517\n",
            "Epoch [140/300], Train Loss: 0.5316, Val Loss: 0.5500\n",
            "Epoch [150/300], Train Loss: 0.5312, Val Loss: 0.5492\n",
            "Epoch [160/300], Train Loss: 0.5309, Val Loss: 0.5489\n",
            "Epoch [170/300], Train Loss: 0.5306, Val Loss: 0.5486\n",
            "Epoch [180/300], Train Loss: 0.5303, Val Loss: 0.5484\n",
            "Epoch [190/300], Train Loss: 0.5300, Val Loss: 0.5482\n",
            "Epoch [200/300], Train Loss: 0.5297, Val Loss: 0.5478\n",
            "Epoch [210/300], Train Loss: 0.5294, Val Loss: 0.5475\n",
            "Epoch [220/300], Train Loss: 0.5291, Val Loss: 0.5471\n",
            "Epoch [230/300], Train Loss: 0.5288, Val Loss: 0.5468\n",
            "Epoch [240/300], Train Loss: 0.5285, Val Loss: 0.5465\n",
            "Epoch [250/300], Train Loss: 0.5282, Val Loss: 0.5462\n",
            "Epoch [260/300], Train Loss: 0.5278, Val Loss: 0.5458\n",
            "Epoch [270/300], Train Loss: 0.5275, Val Loss: 0.5455\n",
            "Epoch [280/300], Train Loss: 0.5272, Val Loss: 0.5452\n",
            "Epoch [290/300], Train Loss: 0.5268, Val Loss: 0.5448\n",
            "Epoch [300/300], Train Loss: 0.5265, Val Loss: 0.5445\n",
            "Fold 10 Test Metrics: {'accuracy': 0.7525035765379113, 'precision': 0.7614841001079933, 'recall': 0.7525035765379113, 'f1': 0.755920591596044, 'auroc': np.float64(0.9164285634069752), 'confusion_matrix': array([[161,   0,  66],\n",
            "       [ 16, 198,  19],\n",
            "       [ 60,  12, 167]])}\n",
            "Class distribution (train): (array([0, 1, 2]), array([1297, 1285, 1331]))\n",
            "Class distribution (test): (array([0, 1, 2]), array([227, 233, 239]))\n",
            "Final Test Metrics: [{'accuracy': 0.7396280400572246, 'precision': 0.7533098431388323, 'recall': 0.7396280400572246, 'f1': 0.743941274844987, 'auroc': np.float64(0.8977619603707641), 'confusion_matrix': array([[168,   1,  58],\n",
            "       [ 18, 191,  24],\n",
            "       [ 72,   9, 158]])}, {'accuracy': 0.7367668097281831, 'precision': 0.7464279288226718, 'recall': 0.7367668097281831, 'f1': 0.740140412433137, 'auroc': np.float64(0.9101696512463283), 'confusion_matrix': array([[163,   5,  59],\n",
            "       [ 19, 192,  22],\n",
            "       [ 68,  11, 160]])}, {'accuracy': 0.6952789699570815, 'precision': 0.7319324049414602, 'recall': 0.6952789699570815, 'f1': 0.6959010118114961, 'auroc': np.float64(0.882430520874891), 'confusion_matrix': array([[108,   6, 113],\n",
            "       [  3, 186,  44],\n",
            "       [ 40,   7, 192]])}, {'accuracy': 0.7010014306151645, 'precision': 0.7117961536148878, 'recall': 0.7010014306151645, 'f1': 0.7052711802494667, 'auroc': np.float64(0.8780759285941498), 'confusion_matrix': array([[148,   3,  76],\n",
            "       [ 13, 192,  28],\n",
            "       [ 75,  14, 150]])}, {'accuracy': 0.7410586552217453, 'precision': 0.7519460121452346, 'recall': 0.7410586552217453, 'f1': 0.7443078741935628, 'auroc': np.float64(0.8976742216735847), 'confusion_matrix': array([[168,   7,  52],\n",
            "       [ 20, 193,  20],\n",
            "       [ 74,   8, 157]])}, {'accuracy': 0.6752503576537912, 'precision': 0.6907352956760051, 'recall': 0.6752503576537912, 'f1': 0.6794144251404286, 'auroc': np.float64(0.8499219618591998), 'confusion_matrix': array([[123,  11,  93],\n",
            "       [  7, 189,  37],\n",
            "       [ 72,   7, 160]])}, {'accuracy': 0.6967095851216023, 'precision': 0.7084711643397965, 'recall': 0.6967095851216023, 'f1': 0.7009857155243422, 'auroc': np.float64(0.8639718068125074), 'confusion_matrix': array([[151,  11,  65],\n",
            "       [ 17, 189,  27],\n",
            "       [ 85,   7, 147]])}, {'accuracy': 0.7424892703862661, 'precision': 0.7535562348285011, 'recall': 0.7424892703862661, 'f1': 0.7466460270333982, 'auroc': np.float64(0.9081128456379037), 'confusion_matrix': array([[158,   1,  68],\n",
            "       [ 15, 197,  21],\n",
            "       [ 66,   9, 164]])}, {'accuracy': 0.7439198855507868, 'precision': 0.7591494734678985, 'recall': 0.7439198855507868, 'f1': 0.7490050399250213, 'auroc': np.float64(0.9089796160335698), 'confusion_matrix': array([[163,   1,  63],\n",
            "       [ 21, 192,  20],\n",
            "       [ 68,   6, 165]])}, {'accuracy': 0.7525035765379113, 'precision': 0.7614841001079933, 'recall': 0.7525035765379113, 'f1': 0.755920591596044, 'auroc': np.float64(0.9164285634069752), 'confusion_matrix': array([[161,   0,  66],\n",
            "       [ 16, 198,  19],\n",
            "       [ 60,  12, 167]])}]\n",
            "Final epoch's number\n",
            "\n",
            "Processing window=30, timestep=3\n",
            "\n",
            "--- Fold 1/10 ---\n",
            "Epoch [10/300], Train Loss: 0.8957, Val Loss: 0.8474\n",
            "Epoch [20/300], Train Loss: 0.7695, Val Loss: 0.7219\n",
            "Epoch [30/300], Train Loss: 0.7433, Val Loss: 0.6863\n",
            "Epoch [40/300], Train Loss: 0.7034, Val Loss: 0.6551\n",
            "Epoch [50/300], Train Loss: 0.6669, Val Loss: 0.6251\n"
          ]
        }
      ],
      "source": [
        "# Основной цикл обучения остается таким же, но теперь работает с 3 классами\n",
        "!mkdir -p /content/drive/MyDrive/Thesis/Results\n",
        "all_steps = None\n",
        "all_results = None\n",
        "log_file = \"/content/drive/MyDrive/Thesis/Results/multiclass_log_v1_1h.txt\"\n",
        "\n",
        "with open(log_file, \"a\") as f:\n",
        "    f.write(\"Training Log - \" + datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\") + \"\\n\\n\")\n",
        "\n",
        "#run_multiclass_experiment(path, 0, 1)\n",
        "\n",
        "for window in range(15, 46, 15):\n",
        "    for timestep in range(2, 9):\n",
        "      if window == 15 and timestep < 8:\n",
        "        continue\n",
        "      run_multiclass_experiment(path, window, timestep)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}